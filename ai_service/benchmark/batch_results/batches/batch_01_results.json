[
  {
    "id": "q1",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 主要面向哪三类设备进行模型部署？",
    "answer": "根据参考资料，TensorFlow Lite 主要面向以下三类设备进行模型部署：  \n1. **移动设备**（如 Android、iOS 设备）  \n2. **嵌入式设备**  \n3. **物联网（IoT）设备**（包括极小的 MCU 设备）  \n\n（依据：内容1、内容2 和 内容4 中均明确提到这三类设备。）",
    "retrieve_time": 0.49077439308166504,
    "generate_time": 6.884185552597046,
    "total_time": 7.374959945678711,
    "tokens_out": 80,
    "tokens_in": 277,
    "ground_truth": "移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）",
    "context": [
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      }
    ]
  },
  {
    "id": "q2",
    "model": "deepseek-v3",
    "query": "全球约有多少台设备部署了 TensorFlow Lite？",
    "answer": "根据参考资料，全球有超过40亿台设备部署了TensorFlow Lite（如内容1、2、4所述）。这一数据在多个来源中一致提及，可信度较高。",
    "retrieve_time": 0.21992778778076172,
    "generate_time": 5.077160120010376,
    "total_time": 5.297087907791138,
    "tokens_out": 38,
    "tokens_in": 292,
    "ground_truth": "超过 40 亿台设备",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "全球有超过40亿的设备上部署的TFLight",
        "source": "1112_222613.mp4 309.8-314.6s"
      }
    ]
  },
  {
    "id": "q3",
    "model": "deepseek-v3",
    "query": "示例花卉分类项目优化并部署的核心模型是什么？",
    "answer": "该花卉分类项目优化并部署的核心模型是 **MobileNet V2**。它是一个基于深度可分离卷积的轻量级神经网络架构，适用于图像分类任务（如花卉识别）。项目通过迁移学习利用其在ImageNet-1000上的预训练权重，并在TensorFlow Lite中优化后部署到Android设备。",
    "retrieve_time": 0.27430105209350586,
    "generate_time": 6.463491201400757,
    "total_time": 6.737792253494263,
    "tokens_out": 67,
    "tokens_in": 234,
    "ground_truth": "MobileNet（MobileNet V2）",
    "context": [
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段"
      },
      {
        "content": "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q4",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 的两大核心组件是什么？",
    "answer": "根据提供的参考资料，TensorFlow Lite的两大核心组件在内容1中明确提及，但具体名称未在片段中完整列出。其他内容（如8.2节）可能涉及架构细节，但当前提供的片段未直接回答该问题。因此，基于现有资料无法确定两大组件的具体名称。\n\n回答：资料中未明确说明两大核心组件的名称。",
    "retrieve_time": 0.2716498374938965,
    "generate_time": 6.73298192024231,
    "total_time": 7.004631757736206,
    "tokens_out": 78,
    "tokens_in": 117,
    "ground_truth": "Converter（转换器）和 Interpreter（解释器）",
    "context": [
      {
        "content": "TensorFlow Lite 包括两个主要组件：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      },
      {
        "content": "8.2.1 TensorFlow Lite整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段"
      }
    ]
  },
  {
    "id": "q5",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 使用哪种序列化格式存储模型文件？",
    "answer": "TensorFlow Lite 使用 FlatBuffers 序列化格式存储模型文件，文件扩展名为 .tflite。这种格式具有内存高效、支持内存直接映射读取等优势，适用于移动设备等资源受限的环境。",
    "retrieve_time": 0.30379438400268555,
    "generate_time": 5.797494173049927,
    "total_time": 6.101288557052612,
    "tokens_out": 46,
    "tokens_in": 278,
    "ground_truth": "FlatBuffers",
    "context": [
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      }
    ]
  },
  {
    "id": "q6",
    "model": "deepseek-v3",
    "query": "Google 在 2017 年底发布了哪款专为移动端设计的深度学习工具？",
    "answer": "Google 在 2017 年底发布了 **TensorFlow Lite**，这是一款专为移动端及 IoT 设备设计的轻量、快速、兼容度高的深度学习工具。",
    "retrieve_time": 0.3037135601043701,
    "generate_time": 5.630397319793701,
    "total_time": 5.934110879898071,
    "tokens_out": 37,
    "tokens_in": 350,
    "ground_truth": "TensorFlow Lite",
    "context": [
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
        "source": "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s"
      },
      {
        "content": "Google开始了TF Mobile项目",
        "source": "1112_222613.mp4 145.9-149.4s"
      },
      {
        "content": "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段"
      }
    ]
  },
  {
    "id": "q7",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为多少？",
    "answer": "根据参考资料，TensorFlow Lite 在 32 位 ARM 平台下的典型二进制大小约为 **1 MB**（包含所有标准算子）。若仅支持常见图像分类模型（如 InceptionV3 和 MobileNet）所需的运算符，则可进一步缩减至 **300 KB 以下**。在极简配置（如仅核心运行时）下，库大小可低至 **100 KB 左右**。",
    "retrieve_time": 0.27318882942199707,
    "generate_time": 6.824326038360596,
    "total_time": 7.097514867782593,
    "tokens_out": 86,
    "tokens_in": 292,
    "ground_truth": "约 1 MB（仅常用算子时小于 300 KB）",
    "context": [
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q8",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 可以利用 Android 系统提供的哪项 API 进行硬件加速？",
    "answer": "TensorFlow Lite 可以利用 Android 系统提供的 **Android 神经网络 API（Android NN API）** 进行硬件加速。该接口允许硬件厂商扩展支持，从而提升模型在设备上的推断性能。",
    "retrieve_time": 0.27391815185546875,
    "generate_time": 5.644192218780518,
    "total_time": 5.918110370635986,
    "tokens_out": 42,
    "tokens_in": 210,
    "ground_truth": "Android NN API（Android 神经网络 API）",
    "context": [
      {
        "content": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      }
    ]
  },
  {
    "id": "q9",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 模型转换的命令行工具名称是什么？",
    "answer": "TensorFlow Lite 模型转换的命令行工具名称是 **tflite_convert**。",
    "retrieve_time": 0.2577643394470215,
    "generate_time": 4.840442895889282,
    "total_time": 5.098207235336304,
    "tokens_out": 19,
    "tokens_in": 135,
    "ground_truth": "tflite_convert",
    "context": [
      {
        "content": "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段"
      },
      {
        "content": "掌握TensorFlow Lite转换器作用",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段"
      },
      {
        "content": "TensorFlow Lite 转换器(Converter)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段"
      },
      {
        "content": "使用TFLite转换器转换模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段"
      }
    ]
  },
  {
    "id": "q10",
    "model": "deepseek-v3",
    "query": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？",
    "answer": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用 `tf.lite.TFLiteConverter` 类，具体调用其 `from_saved_model()` 方法。示例代码如下：\n\n```python\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n```\n\n其中 `saved_model_dir` 是 SavedModel 的目录路径。",
    "retrieve_time": 0.17171478271484375,
    "generate_time": 7.050820350646973,
    "total_time": 7.222535133361816,
    "tokens_out": 80,
    "tokens_in": 185,
    "ground_truth": "tf.lite.TFLiteConverter",
    "context": [
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段"
      },
      {
        "content": "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段"
      }
    ]
  },
  {
    "id": "q11",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 的 GPU 委托在 Java 侧创建时使用的类名是什么？",
    "answer": "在 Java 侧创建 TensorFlow Lite 的 GPU 委托时使用的类名是 `GpuDelegate`。",
    "retrieve_time": 0.25752997398376465,
    "generate_time": 4.463320255279541,
    "total_time": 4.720850229263306,
    "tokens_out": 24,
    "tokens_in": 182,
    "ground_truth": "GpuDelegate",
    "context": [
      {
        "content": "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段"
      },
      {
        "content": "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段"
      },
      {
        "content": "tfliteOptions.addDelegate(gpuDelegate);",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段"
      },
      {
        "content": "GpuDelegate delegate = new GpuDelegate();",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段"
      }
    ]
  },
  {
    "id": "q12",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 量化（quantization）主要带来哪两方面的好处？",
    "answer": "根据参考资料，TensorFlow Lite 量化的主要好处包括以下两方面：\n\n1. **降低权重的精确表示**：通过量化技术减少权重的精度（例如从32位浮点转为8位整数），从而减小模型大小。\n2. **降低存储和计算的激活值**（可选）：可进一步优化激活值的存储与计算开销，提升推理效率。\n\n（依据内容4总结）",
    "retrieve_time": 0.18056702613830566,
    "generate_time": 7.598060131072998,
    "total_time": 7.778627157211304,
    "tokens_out": 82,
    "tokens_in": 187,
    "ground_truth": "减少模型大小和提升推理性能",
    "context": [
      {
        "content": "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段"
      },
      {
        "content": "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段"
      }
    ]
  },
  {
    "id": "q13",
    "model": "deepseek-v3",
    "query": "示例中使用 ImageDataGenerator 加载数据时将 validation_split 设置为多少？",
    "answer": "根据提供的参考资料，没有明确提到 `validation_split` 的具体设置值。因此，无法确定示例中使用的具体数值。",
    "retrieve_time": 0.2608833312988281,
    "generate_time": 4.464146852493286,
    "total_time": 4.725030183792114,
    "tokens_out": 26,
    "tokens_in": 244,
    "ground_truth": "0.2（20% 用于验证集）",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段"
      },
      {
        "content": "validation_data=val_generator,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q14",
    "model": "deepseek-v3",
    "query": "在花卉识别示例中输入图像被缩放到的尺寸是多少？",
    "answer": "根据提供的参考资料，没有明确提及输入图像被缩放到的具体尺寸。因此，我无法回答这个问题。",
    "retrieve_time": 0.17853116989135742,
    "generate_time": 4.903367519378662,
    "total_time": 5.0818986892700195,
    "tokens_out": 22,
    "tokens_in": 136,
    "ground_truth": "224×224",
    "context": [
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      },
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      }
    ]
  },
  {
    "id": "q15",
    "model": "deepseek-v3",
    "query": "该花卉识别应用最终需要识别多少种花？",
    "answer": "根据提供的参考资料，没有明确提及该花卉识别应用需要识别的具体花卉种类数量。因此，我无法回答这个问题。",
    "retrieve_time": 0.16751337051391602,
    "generate_time": 5.115084409713745,
    "total_time": 5.282597780227661,
    "tokens_out": 26,
    "tokens_in": 138,
    "ground_truth": "四种花",
    "context": [
      {
        "content": "图8-6 花卉识别app",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段"
      },
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q16",
    "model": "deepseek-v3",
    "query": "Keras ImageDataGenerator 中用于按文件夹加载图像的函数是什么？",
    "answer": "在 Keras 中，`ImageDataGenerator` 类提供的用于按文件夹加载图像的函数是 `flow_from_directory()`。该函数会自动根据文件夹结构加载图像数据，并支持批量生成图像及其标签。\n\n示例用法：\n```python\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator()\ntrain_generator = datagen.flow_from_directory(\n    directory='path/to/train_data',\n    target_size=(256, 256),\n    batch_size=32,\n    class_mode='categorical'\n)\n```\n\n该函数会自动将每个子文件夹视为一个类别，并返回输入图像和对应的标签。",
    "retrieve_time": 0.28592777252197266,
    "generate_time": 9.789477586746216,
    "total_time": 10.075405359268188,
    "tokens_out": 127,
    "tokens_in": 188,
    "ground_truth": "flow_from_directory",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "Kirons提供了Image Data Generator类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s"
      },
      {
        "content": "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q17",
    "model": "deepseek-v3",
    "query": "示例中训练时的 batch_size 被设置为多少？",
    "answer": "根据参考资料，示例中训练时的 `batch_size` 默认值为 **32**。若用户未显式修改该值（如通过 `BATCH_SIZE` 变量赋值），则实际值即为默认值 32。若代码中通过 `BATCH_SIZE` 进行了设置（如 `batch_size=BATCH_SIZE`），则需进一步查看 `BATCH_SIZE` 的具体定义才能确定实际值。当前资料未提供 `BATCH_SIZE` 的赋值信息，因此无法确认是否被修改。",
    "retrieve_time": 0.3227076530456543,
    "generate_time": 8.435611009597778,
    "total_time": 8.758318662643433,
    "tokens_out": 107,
    "tokens_in": 154,
    "ground_truth": "64",
    "context": [
      {
        "content": "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段"
      },
      {
        "content": "BatchSize 默认为32",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段"
      }
    ]
  },
  {
    "id": "q18",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 模型文件的默认扩展名是什么？",
    "answer": "TensorFlow Lite 模型文件的默认扩展名是 `.tflite`。",
    "retrieve_time": 0.2791569232940674,
    "generate_time": 5.249997138977051,
    "total_time": 5.529154062271118,
    "tokens_out": 16,
    "tokens_in": 230,
    "ground_truth": ".tflite",
    "context": [
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "return \"model.tflite\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      }
    ]
  },
  {
    "id": "q19",
    "model": "deepseek-v3",
    "query": "Python 示例中使用哪行代码将量化优化应用于转换器？",
    "answer": "根据参考资料，将量化优化应用于转换器的代码是：\n\n```python\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n```\n\n或\n\n```python\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n```\n\n具体取决于使用的优化选项（参考资料 2 和 4）。",
    "retrieve_time": 0.24272799491882324,
    "generate_time": 6.480541944503784,
    "total_time": 6.723269939422607,
    "tokens_out": 71,
    "tokens_in": 171,
    "ground_truth": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "context": [
      {
        "content": "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "tflite_quant_model = converter.convert()",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段"
      },
      {
        "content": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段"
      }
    ]
  },
  {
    "id": "q20",
    "model": "deepseek-v3",
    "query": "描述 TensorFlow Lite 模型格式的 schema 文件名是什么？",
    "answer": "根据参考资料，TensorFlow Lite 模型格式的 schema 文件名是 **schema.fbs**（如内容1和内容3所述）。该文件使用 FlatBuffers 定义了 TFLite 模型文件格式。",
    "retrieve_time": 0.29809141159057617,
    "generate_time": 5.628936767578125,
    "total_time": 5.927028179168701,
    "tokens_out": 44,
    "tokens_in": 245,
    "ground_truth": "schema.fbs",
    "context": [
      {
        "content": "图8-2 TFLite schema.fbs样例代码",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段"
      },
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      }
    ]
  },
  {
    "id": "q1",
    "model": "qwen-max",
    "query": "TensorFlow Lite 主要面向哪三类设备进行模型部署？",
    "answer": "TensorFlow Lite 主要面向三类设备进行模型部署：移动设备（如智能手机）、嵌入式设备以及物联网(IoT)设备。",
    "retrieve_time": 0.27989745140075684,
    "generate_time": 2.5724968910217285,
    "total_time": 2.8523943424224854,
    "tokens_out": 31,
    "tokens_in": 299,
    "ground_truth": "移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）",
    "context": [
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      }
    ]
  },
  {
    "id": "q2",
    "model": "qwen-max",
    "query": "全球约有多少台设备部署了 TensorFlow Lite？",
    "answer": "全球超过40亿的设备上部署了TensorFlow Lite。",
    "retrieve_time": 0.33075666427612305,
    "generate_time": 3.204460620880127,
    "total_time": 3.53521728515625,
    "tokens_out": 14,
    "tokens_in": 307,
    "ground_truth": "超过 40 亿台设备",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "全球有超过40亿的设备上部署的TFLight",
        "source": "1112_222613.mp4 309.8-314.6s"
      }
    ]
  },
  {
    "id": "q3",
    "model": "qwen-max",
    "query": "示例花卉分类项目优化并部署的核心模型是什么？",
    "answer": "核心模型是MobileNet V2。此项目基于该模型通过迁移学习实现花卉识别，并进一步使用TensorFlow Lite对该模型进行优化，以便能够在Android手机上部署。",
    "retrieve_time": 0.1665184497833252,
    "generate_time": 3.741170883178711,
    "total_time": 3.907689332962036,
    "tokens_out": 37,
    "tokens_in": 251,
    "ground_truth": "MobileNet（MobileNet V2）",
    "context": [
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段"
      },
      {
        "content": "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q4",
    "model": "qwen-max",
    "query": "TensorFlow Lite 的两大核心组件是什么？",
    "answer": "根据提供的参考资料，虽然提到“TensorFlow Lite 包括两个主要组件”，但具体的两大核心组件名称未被直接列出。因此，基于当前给定的信息，我无法准确指出 TensorFlow Lite 的两大核心组件是什么。如果您可以提供更多相关信息或允许我参考其他资料，我会很乐意提供更详细的答案。",
    "retrieve_time": 0.1873762607574463,
    "generate_time": 3.5593502521514893,
    "total_time": 3.7467265129089355,
    "tokens_out": 67,
    "tokens_in": 118,
    "ground_truth": "Converter（转换器）和 Interpreter（解释器）",
    "context": [
      {
        "content": "TensorFlow Lite 包括两个主要组件：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      },
      {
        "content": "8.2.1 TensorFlow Lite整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段"
      }
    ]
  },
  {
    "id": "q5",
    "model": "qwen-max",
    "query": "TensorFlow Lite 使用哪种序列化格式存储模型文件？",
    "answer": "TensorFlow Lite 使用 FlatBuffers 作为其模型文件的序列化格式。这种格式特别适合于需要高效内存使用和快速访问数据的应用场景，比如在移动设备上运行机器学习模型。",
    "retrieve_time": 0.1433713436126709,
    "generate_time": 4.181831359863281,
    "total_time": 4.325202703475952,
    "tokens_out": 42,
    "tokens_in": 301,
    "ground_truth": "FlatBuffers",
    "context": [
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      }
    ]
  },
  {
    "id": "q6",
    "model": "qwen-max",
    "query": "Google 在 2017 年底发布了哪款专为移动端设计的深度学习工具？",
    "answer": "Google 在 2017 年底发布了 TensorFlow Lite，这是一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具。",
    "retrieve_time": 0.21873688697814941,
    "generate_time": 2.190359592437744,
    "total_time": 2.4090964794158936,
    "tokens_out": 33,
    "tokens_in": 380,
    "ground_truth": "TensorFlow Lite",
    "context": [
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
        "source": "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s"
      },
      {
        "content": "Google开始了TF Mobile项目",
        "source": "1112_222613.mp4 145.9-149.4s"
      },
      {
        "content": "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段"
      }
    ]
  },
  {
    "id": "q7",
    "model": "qwen-max",
    "query": "TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为多少？",
    "answer": "TensorFlow Lite 典型 ARM 32 位构建的二进制文件大小约为 1 MB。如果仅包含支持特定模型（如 InceptionV3 和 MobileNet）所需的运算符，则其大小可以减少到不到 300 KB。",
    "retrieve_time": 0.1739504337310791,
    "generate_time": 9.240682125091553,
    "total_time": 9.414632558822632,
    "tokens_out": 56,
    "tokens_in": 330,
    "ground_truth": "约 1 MB（仅常用算子时小于 300 KB）",
    "context": [
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q8",
    "model": "qwen-max",
    "query": "TensorFlow Lite 可以利用 Android 系统提供的哪项 API 进行硬件加速？",
    "answer": "TensorFlow Lite 可以利用 Android 神经网络 API（Android NN API）进行硬件加速。这项API让硬件厂商能够扩展支持，从而更好地利用手机上的加速器，如GPU或DSP等。",
    "retrieve_time": 0.2725088596343994,
    "generate_time": 2.1071131229400635,
    "total_time": 2.379621982574463,
    "tokens_out": 46,
    "tokens_in": 229,
    "ground_truth": "Android NN API（Android 神经网络 API）",
    "context": [
      {
        "content": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      }
    ]
  },
  {
    "id": "q9",
    "model": "qwen-max",
    "query": "TensorFlow Lite 模型转换的命令行工具名称是什么？",
    "answer": "TensorFlow Lite 模型转换的命令行工具名称是 `tflite_convert`。",
    "retrieve_time": 0.15047883987426758,
    "generate_time": 1.4083325862884521,
    "total_time": 1.5588114261627197,
    "tokens_out": 20,
    "tokens_in": 144,
    "ground_truth": "tflite_convert",
    "context": [
      {
        "content": "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段"
      },
      {
        "content": "掌握TensorFlow Lite转换器作用",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段"
      },
      {
        "content": "TensorFlow Lite 转换器(Converter)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段"
      },
      {
        "content": "使用TFLite转换器转换模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段"
      }
    ]
  },
  {
    "id": "q10",
    "model": "qwen-max",
    "query": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？",
    "answer": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用 `tf.lite.TFLiteConverter` 类。具体来说，可以通过调用 `TFLiteConverter.from_saved_model()` 方法，并传入包含SavedModel的目录路径来创建转换器实例。例如：\n\n```python\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n```\n\n这里的 `saved_model_dir` 是指向你的SavedModel所在目录的路径。",
    "retrieve_time": 0.22139286994934082,
    "generate_time": 5.728466749191284,
    "total_time": 5.949859619140625,
    "tokens_out": 100,
    "tokens_in": 187,
    "ground_truth": "tf.lite.TFLiteConverter",
    "context": [
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段"
      },
      {
        "content": "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段"
      }
    ]
  },
  {
    "id": "q11",
    "model": "qwen-max",
    "query": "TensorFlow Lite 的 GPU 委托在 Java 侧创建时使用的类名是什么？",
    "answer": "在 Java 侧创建 TensorFlow Lite 的 GPU 委托时使用的类名是 `GpuDelegate`。",
    "retrieve_time": 0.27930164337158203,
    "generate_time": 1.080822229385376,
    "total_time": 1.360123872756958,
    "tokens_out": 24,
    "tokens_in": 188,
    "ground_truth": "GpuDelegate",
    "context": [
      {
        "content": "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段"
      },
      {
        "content": "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段"
      },
      {
        "content": "tfliteOptions.addDelegate(gpuDelegate);",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段"
      },
      {
        "content": "GpuDelegate delegate = new GpuDelegate();",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段"
      }
    ]
  },
  {
    "id": "q12",
    "model": "qwen-max",
    "query": "TensorFlow Lite 量化（quantization）主要带来哪两方面的好处？",
    "answer": "根据提供的参考资料，TensorFlow Lite 量化主要带来的两方面好处是：减少模型大小（通过降低权重的精确表示来实现）以及提高计算效率（包括可选地减少存储和计算激活值）。这些优化有助于在资源受限的设备上更高效地运行模型。",
    "retrieve_time": 0.1819934844970703,
    "generate_time": 6.35138726234436,
    "total_time": 6.533380746841431,
    "tokens_out": 60,
    "tokens_in": 193,
    "ground_truth": "减少模型大小和提升推理性能",
    "context": [
      {
        "content": "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段"
      },
      {
        "content": "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段"
      }
    ]
  },
  {
    "id": "q13",
    "model": "qwen-max",
    "query": "示例中使用 ImageDataGenerator 加载数据时将 validation_split 设置为多少？",
    "answer": "根据提供的参考资料，没有明确提到`validation_split`的具体数值。因此，基于现有信息无法确定`ImageDataGenerator`加载数据时`validation_split`被设置为了多少。如果需要使用`validation_split`参数来自动生成验证集的话，通常这个值会根据具体需求来设定，比如设为0.2意味着将20%的数据用于验证。但请注意，在您的情况下，看起来训练集和验证集是通过手动划分目录来区分的，而不是通过`validation_split`自动完成的。",
    "retrieve_time": 0.27186155319213867,
    "generate_time": 6.9766716957092285,
    "total_time": 7.248533248901367,
    "tokens_out": 107,
    "tokens_in": 270,
    "ground_truth": "0.2（20% 用于验证集）",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段"
      },
      {
        "content": "validation_data=val_generator,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q14",
    "model": "qwen-max",
    "query": "在花卉识别示例中输入图像被缩放到的尺寸是多少？",
    "answer": "根据提供的参考资料，没有具体提到花卉识别示例中输入图像被缩放到的具体尺寸。因此，我无法直接从给定的信息中给出准确的答案。如果您有更详细的资料或上下文信息，请提供，这样或许能够帮助找到答案。对于使用MobileNet V2这样的模型来说，通常会有一个推荐的输入尺寸（比如224x224像素），但这并不意味着您的案例一定遵循了这个标准，除非在您提供的额外材料中有明确指出。",
    "retrieve_time": 0.2666659355163574,
    "generate_time": 11.261526823043823,
    "total_time": 11.52819275856018,
    "tokens_out": 102,
    "tokens_in": 145,
    "ground_truth": "224×224",
    "context": [
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      },
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      }
    ]
  },
  {
    "id": "q15",
    "model": "qwen-max",
    "query": "该花卉识别应用最终需要识别多少种花？",
    "answer": "根据提供的参考资料，没有具体提到该花卉识别应用最终需要识别多少种花。因此，我无法给出具体的答案。如果您有更多相关信息或资料，请提供给我，这样或许能帮助更准确地回答您的问题。",
    "retrieve_time": 0.28566479682922363,
    "generate_time": 3.000068187713623,
    "total_time": 3.2857329845428467,
    "tokens_out": 47,
    "tokens_in": 147,
    "ground_truth": "四种花",
    "context": [
      {
        "content": "图8-6 花卉识别app",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段"
      },
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q16",
    "model": "qwen-max",
    "query": "Keras ImageDataGenerator 中用于按文件夹加载图像的函数是什么？",
    "answer": "Keras 的 `ImageDataGenerator` 类本身并不直接提供一个特定的函数来按文件夹加载图像，但你可以结合使用 `flow_from_directory` 方法来从指定的目录结构中加载图片。这个方法能够自动根据文件夹的名字来分类图片，并生成批次的数据供给训练或验证模型使用。因此，如果你想要按照文件夹组织结构来加载图像数据的话，应该使用的是 `flow_from_directory()` 方法。",
    "retrieve_time": 0.19366455078125,
    "generate_time": 4.918632507324219,
    "total_time": 5.112297058105469,
    "tokens_out": 90,
    "tokens_in": 196,
    "ground_truth": "flow_from_directory",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "Kirons提供了Image Data Generator类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s"
      },
      {
        "content": "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q17",
    "model": "qwen-max",
    "query": "示例中训练时的 batch_size 被设置为多少？",
    "answer": "根据提供的资料，训练时的`batch_size`被设置为了64。这是从内容1中直接获得的信息：“该值设置为64”。",
    "retrieve_time": 0.17928171157836914,
    "generate_time": 3.743858814239502,
    "total_time": 3.923140525817871,
    "tokens_out": 33,
    "tokens_in": 166,
    "ground_truth": "64",
    "context": [
      {
        "content": "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段"
      },
      {
        "content": "BatchSize 默认为32",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段"
      }
    ]
  },
  {
    "id": "q18",
    "model": "qwen-max",
    "query": "TensorFlow Lite 模型文件的默认扩展名是什么？",
    "answer": "TensorFlow Lite 模型文件的默认扩展名是 `.tflite`。",
    "retrieve_time": 0.14692401885986328,
    "generate_time": 1.6282846927642822,
    "total_time": 1.7752087116241455,
    "tokens_out": 18,
    "tokens_in": 256,
    "ground_truth": ".tflite",
    "context": [
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "return \"model.tflite\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      }
    ]
  },
  {
    "id": "q19",
    "model": "qwen-max",
    "query": "Python 示例中使用哪行代码将量化优化应用于转换器？",
    "answer": "在提供的参考资料中，用于将量化优化应用于转换器的代码是：\n\n```python\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n```\n\n或者，如果目的是更具体地优化模型大小，则可以使用：\n\n```python\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n```\n\n这两行代码都展示了如何设置`converter.optimizations`属性来启用特定类型的量化。第一种方式使用默认优化策略，而第二种则特别针对减少模型尺寸进行优化。",
    "retrieve_time": 0.16840195655822754,
    "generate_time": 8.290884256362915,
    "total_time": 8.459286212921143,
    "tokens_out": 108,
    "tokens_in": 174,
    "ground_truth": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "context": [
      {
        "content": "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "tflite_quant_model = converter.convert()",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段"
      },
      {
        "content": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段"
      }
    ]
  },
  {
    "id": "q20",
    "model": "qwen-max",
    "query": "描述 TensorFlow Lite 模型格式的 schema 文件名是什么？",
    "answer": "根据提供的参考资料，TensorFlow Lite 模型格式的 schema 文件名为 `schema.fbs`。这个文件使用 FlatBuffers 来定义 TFLite 模型文件的具体格式。",
    "retrieve_time": 0.22599315643310547,
    "generate_time": 2.6808576583862305,
    "total_time": 2.906850814819336,
    "tokens_out": 39,
    "tokens_in": 264,
    "ground_truth": "schema.fbs",
    "context": [
      {
        "content": "图8-2 TFLite schema.fbs样例代码",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段"
      },
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      }
    ]
  },
  {
    "id": "q1",
    "model": "glm-4",
    "query": "TensorFlow Lite 主要面向哪三类设备进行模型部署？",
    "answer": "TensorFlow Lite 主要面向移动设备、嵌入式设备和物联网（IoT）设备进行模型部署。",
    "retrieve_time": 0.2595031261444092,
    "generate_time": 1.3781514167785645,
    "total_time": 1.6376545429229736,
    "tokens_out": 22,
    "tokens_in": 280,
    "ground_truth": "移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）",
    "context": [
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      }
    ]
  },
  {
    "id": "q2",
    "model": "glm-4",
    "query": "全球约有多少台设备部署了 TensorFlow Lite？",
    "answer": "全球超过40亿台设备部署了TensorFlow Lite。",
    "retrieve_time": 0.17098569869995117,
    "generate_time": 0.8237044811248779,
    "total_time": 0.9946901798248291,
    "tokens_out": 14,
    "tokens_in": 287,
    "ground_truth": "超过 40 亿台设备",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "全球有超过40亿的设备上部署的TFLight",
        "source": "1112_222613.mp4 309.8-314.6s"
      }
    ]
  },
  {
    "id": "q3",
    "model": "glm-4",
    "query": "示例花卉分类项目优化并部署的核心模型是什么？",
    "answer": "核心模型是MobileNet V2。在迁移学习的基础上，该模型被优化并在Android手机上部署，用于识别四种花卉种类。",
    "retrieve_time": 0.17384743690490723,
    "generate_time": 1.2829797267913818,
    "total_time": 1.456827163696289,
    "tokens_out": 31,
    "tokens_in": 241,
    "ground_truth": "MobileNet（MobileNet V2）",
    "context": [
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段"
      },
      {
        "content": "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q4",
    "model": "glm-4",
    "query": "TensorFlow Lite 的两大核心组件是什么？",
    "answer": "TensorFlow Lite 的两大核心组件在提供的资料中并未直接列出。根据资料的内容编排，相关信息可能包含在“8.2 TensorFlow Lite体系结构”及“8.2.1 TensorFlow Lite整体架构”中。但是，由于具体内容没有给出，我无法准确提供这两个核心组件的名称。建议查阅完整的TensorFlow Lite官方文档或相关资料以获取这一信息。目前我无法提供答案，请谅解。",
    "retrieve_time": 0.15670990943908691,
    "generate_time": 3.2020556926727295,
    "total_time": 3.3587656021118164,
    "tokens_out": 92,
    "tokens_in": 112,
    "ground_truth": "Converter（转换器）和 Interpreter（解释器）",
    "context": [
      {
        "content": "TensorFlow Lite 包括两个主要组件：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      },
      {
        "content": "8.2.1 TensorFlow Lite整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段"
      }
    ]
  },
  {
    "id": "q5",
    "model": "glm-4",
    "query": "TensorFlow Lite 使用哪种序列化格式存储模型文件？",
    "answer": "TensorFlow Lite 使用 FlatBuffers 序列化格式存储模型文件。",
    "retrieve_time": 0.14986777305603027,
    "generate_time": 0.9905068874359131,
    "total_time": 1.1403746604919434,
    "tokens_out": 16,
    "tokens_in": 282,
    "ground_truth": "FlatBuffers",
    "context": [
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      }
    ]
  },
  {
    "id": "q6",
    "model": "glm-4",
    "query": "Google 在 2017 年底发布了哪款专为移动端设计的深度学习工具？",
    "answer": "Google 在 2017 年底发布了 TensorFlow Lite，这是一个专为移动端设计的轻量、快速、兼容度高的深度学习工具。",
    "retrieve_time": 0.17595410346984863,
    "generate_time": 1.4540581703186035,
    "total_time": 1.6300122737884521,
    "tokens_out": 30,
    "tokens_in": 352,
    "ground_truth": "TensorFlow Lite",
    "context": [
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
        "source": "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s"
      },
      {
        "content": "Google开始了TF Mobile项目",
        "source": "1112_222613.mp4 145.9-149.4s"
      },
      {
        "content": "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段"
      }
    ]
  },
  {
    "id": "q7",
    "model": "glm-4",
    "query": "TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为多少？",
    "answer": "TensorFlow Lite 在典型 ARM 32 位构建下的二进制大小约为 1 MB。如果仅使用支持常见图像分类模型（如InceptionV3和MobileNet）所需的运算符，其大小可不到 300 KB。",
    "retrieve_time": 0.15620875358581543,
    "generate_time": 1.858626365661621,
    "total_time": 2.0148351192474365,
    "tokens_out": 51,
    "tokens_in": 294,
    "ground_truth": "约 1 MB（仅常用算子时小于 300 KB）",
    "context": [
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q8",
    "model": "glm-4",
    "query": "TensorFlow Lite 可以利用 Android 系统提供的哪项 API 进行硬件加速？",
    "answer": "TensorFlow Lite 可以利用 Android 系统提供的 Android 神经网络 API（Android NN API）进行硬件加速。",
    "retrieve_time": 0.168670654296875,
    "generate_time": 1.2197425365447998,
    "total_time": 1.3884131908416748,
    "tokens_out": 28,
    "tokens_in": 212,
    "ground_truth": "Android NN API（Android 神经网络 API）",
    "context": [
      {
        "content": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      }
    ]
  },
  {
    "id": "q9",
    "model": "glm-4",
    "query": "TensorFlow Lite 模型转换的命令行工具名称是什么？",
    "answer": "tflite_convert。",
    "retrieve_time": 0.14618206024169922,
    "generate_time": 0.4597160816192627,
    "total_time": 0.6058981418609619,
    "tokens_out": 7,
    "tokens_in": 140,
    "ground_truth": "tflite_convert",
    "context": [
      {
        "content": "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段"
      },
      {
        "content": "掌握TensorFlow Lite转换器作用",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段"
      },
      {
        "content": "TensorFlow Lite 转换器(Converter)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段"
      },
      {
        "content": "使用TFLite转换器转换模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段"
      }
    ]
  },
  {
    "id": "q10",
    "model": "glm-4",
    "query": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？",
    "answer": "应使用 `tf.lite.TFLiteConverter` 类，并通过调用其 `from_saved_model()` 方法来进行转换。",
    "retrieve_time": 0.16807293891906738,
    "generate_time": 1.0565965175628662,
    "total_time": 1.2246694564819336,
    "tokens_out": 27,
    "tokens_in": 182,
    "ground_truth": "tf.lite.TFLiteConverter",
    "context": [
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段"
      },
      {
        "content": "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段"
      }
    ]
  },
  {
    "id": "q11",
    "model": "glm-4",
    "query": "TensorFlow Lite 的 GPU 委托在 Java 侧创建时使用的类名是什么？",
    "answer": "GpuDelegate",
    "retrieve_time": 0.15817904472351074,
    "generate_time": 0.4800698757171631,
    "total_time": 0.6382489204406738,
    "tokens_out": 5,
    "tokens_in": 180,
    "ground_truth": "GpuDelegate",
    "context": [
      {
        "content": "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段"
      },
      {
        "content": "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段"
      },
      {
        "content": "tfliteOptions.addDelegate(gpuDelegate);",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段"
      },
      {
        "content": "GpuDelegate delegate = new GpuDelegate();",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段"
      }
    ]
  },
  {
    "id": "q12",
    "model": "glm-4",
    "query": "TensorFlow Lite 量化（quantization）主要带来哪两方面的好处？",
    "answer": "TensorFlow Lite 量化主要带来的两方面好处是：降低权重的精确表示和减少存储及计算的激活值。这些好处有助于优化模型的大小和提升推理速度，同时尽可能保持模型的准确性。",
    "retrieve_time": 0.19931626319885254,
    "generate_time": 1.6658191680908203,
    "total_time": 1.8651354312896729,
    "tokens_out": 43,
    "tokens_in": 186,
    "ground_truth": "减少模型大小和提升推理性能",
    "context": [
      {
        "content": "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段"
      },
      {
        "content": "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段"
      }
    ]
  },
  {
    "id": "q13",
    "model": "glm-4",
    "query": "示例中使用 ImageDataGenerator 加载数据时将 validation_split 设置为多少？",
    "answer": "不知道。参考资料中没有提供设置 validation_split 的信息。",
    "retrieve_time": 0.16727685928344727,
    "generate_time": 0.7478232383728027,
    "total_time": 0.91510009765625,
    "tokens_out": 13,
    "tokens_in": 254,
    "ground_truth": "0.2（20% 用于验证集）",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段"
      },
      {
        "content": "validation_data=val_generator,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q14",
    "model": "glm-4",
    "query": "在花卉识别示例中输入图像被缩放到的尺寸是多少？",
    "answer": "不知道。参考资料中没有提供输入图像被缩放到的尺寸信息。",
    "retrieve_time": 0.18708586692810059,
    "generate_time": 0.7886662483215332,
    "total_time": 0.9757521152496338,
    "tokens_out": 16,
    "tokens_in": 137,
    "ground_truth": "224×224",
    "context": [
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      },
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      }
    ]
  },
  {
    "id": "q15",
    "model": "glm-4",
    "query": "该花卉识别应用最终需要识别多少种花？",
    "answer": "不知道。参考资料中没有提供该花卉识别应用最终需要识别的花的种类数量。",
    "retrieve_time": 0.550382137298584,
    "generate_time": 0.8439431190490723,
    "total_time": 1.3943252563476562,
    "tokens_out": 18,
    "tokens_in": 139,
    "ground_truth": "四种花",
    "context": [
      {
        "content": "图8-6 花卉识别app",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段"
      },
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q16",
    "model": "glm-4",
    "query": "Keras ImageDataGenerator 中用于按文件夹加载图像的函数是什么？",
    "answer": "不知道。参考资料中没有提供关于 Keras ImageDataGenerator 中用于按文件夹加载图像的具体函数信息。",
    "retrieve_time": 0.15318655967712402,
    "generate_time": 1.0753071308135986,
    "total_time": 1.2284936904907227,
    "tokens_out": 23,
    "tokens_in": 190,
    "ground_truth": "flow_from_directory",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "Kirons提供了Image Data Generator类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s"
      },
      {
        "content": "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q17",
    "model": "glm-4",
    "query": "示例中训练时的 batch_size 被设置为多少？",
    "answer": "示例中训练时的 `batch_size` 被设置为64。",
    "retrieve_time": 0.1628856658935547,
    "generate_time": 0.7750816345214844,
    "total_time": 0.9379673004150391,
    "tokens_out": 16,
    "tokens_in": 155,
    "ground_truth": "64",
    "context": [
      {
        "content": "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段"
      },
      {
        "content": "BatchSize 默认为32",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段"
      }
    ]
  },
  {
    "id": "q18",
    "model": "glm-4",
    "query": "TensorFlow Lite 模型文件的默认扩展名是什么？",
    "answer": "默认扩展名是 .tflite。",
    "retrieve_time": 0.16692399978637695,
    "generate_time": 0.7835135459899902,
    "total_time": 0.9504375457763672,
    "tokens_out": 11,
    "tokens_in": 240,
    "ground_truth": ".tflite",
    "context": [
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "return \"model.tflite\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      }
    ]
  },
  {
    "id": "q19",
    "model": "glm-4",
    "query": "Python 示例中使用哪行代码将量化优化应用于转换器？",
    "answer": "在提供的参考资料中，应用于转换器的量化优化是通过以下代码行实现的：\n\n```python\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n```\n\n这行代码将量化优化应用于转换器，以进行模型转换。",
    "retrieve_time": 0.19124889373779297,
    "generate_time": 1.7969014644622803,
    "total_time": 1.9881503582000732,
    "tokens_out": 51,
    "tokens_in": 169,
    "ground_truth": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "context": [
      {
        "content": "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "tflite_quant_model = converter.convert()",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段"
      },
      {
        "content": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段"
      }
    ]
  },
  {
    "id": "q20",
    "model": "glm-4",
    "query": "描述 TensorFlow Lite 模型格式的 schema 文件名是什么？",
    "answer": "schema.fbs",
    "retrieve_time": 0.1576366424560547,
    "generate_time": 0.5575599670410156,
    "total_time": 0.7151966094970703,
    "tokens_out": 5,
    "tokens_in": 250,
    "ground_truth": "schema.fbs",
    "context": [
      {
        "content": "图8-2 TFLite schema.fbs样例代码",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段"
      },
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      }
    ]
  },
  {
    "id": "q1",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 主要面向哪三类设备进行模型部署？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.5053751468658447,
    "generate_time": 0.26442980766296387,
    "total_time": 0.7698049545288086,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）",
    "context": [
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      }
    ]
  },
  {
    "id": "q2",
    "model": "baichuan2-13b-chat",
    "query": "全球约有多少台设备部署了 TensorFlow Lite？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.15247631072998047,
    "generate_time": 0.0936591625213623,
    "total_time": 0.24613547325134277,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "超过 40 亿台设备",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "全球有超过40亿的设备上部署的TFLight",
        "source": "1112_222613.mp4 309.8-314.6s"
      }
    ]
  },
  {
    "id": "q3",
    "model": "baichuan2-13b-chat",
    "query": "示例花卉分类项目优化并部署的核心模型是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.14923715591430664,
    "generate_time": 0.10059380531311035,
    "total_time": 0.249830961227417,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "MobileNet（MobileNet V2）",
    "context": [
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段"
      },
      {
        "content": "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q4",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 的两大核心组件是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.15766668319702148,
    "generate_time": 0.09289312362670898,
    "total_time": 0.25055980682373047,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "Converter（转换器）和 Interpreter（解释器）",
    "context": [
      {
        "content": "TensorFlow Lite 包括两个主要组件：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      },
      {
        "content": "8.2.1 TensorFlow Lite整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段"
      }
    ]
  },
  {
    "id": "q5",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 使用哪种序列化格式存储模型文件？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.17752695083618164,
    "generate_time": 0.5610268115997314,
    "total_time": 0.7385537624359131,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "FlatBuffers",
    "context": [
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      }
    ]
  },
  {
    "id": "q6",
    "model": "baichuan2-13b-chat",
    "query": "Google 在 2017 年底发布了哪款专为移动端设计的深度学习工具？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.16207551956176758,
    "generate_time": 0.2681245803833008,
    "total_time": 0.43020009994506836,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "TensorFlow Lite",
    "context": [
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
        "source": "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s"
      },
      {
        "content": "Google开始了TF Mobile项目",
        "source": "1112_222613.mp4 145.9-149.4s"
      },
      {
        "content": "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段"
      }
    ]
  },
  {
    "id": "q7",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为多少？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.15807604789733887,
    "generate_time": 0.09550690650939941,
    "total_time": 0.2535829544067383,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "约 1 MB（仅常用算子时小于 300 KB）",
    "context": [
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q8",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 可以利用 Android 系统提供的哪项 API 进行硬件加速？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.19861721992492676,
    "generate_time": 0.08953976631164551,
    "total_time": 0.28815698623657227,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "Android NN API（Android 神经网络 API）",
    "context": [
      {
        "content": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      }
    ]
  },
  {
    "id": "q9",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 模型转换的命令行工具名称是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.19458937644958496,
    "generate_time": 0.09274506568908691,
    "total_time": 0.2873344421386719,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "tflite_convert",
    "context": [
      {
        "content": "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段"
      },
      {
        "content": "掌握TensorFlow Lite转换器作用",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段"
      },
      {
        "content": "TensorFlow Lite 转换器(Converter)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段"
      },
      {
        "content": "使用TFLite转换器转换模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段"
      }
    ]
  },
  {
    "id": "q10",
    "model": "baichuan2-13b-chat",
    "query": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.17218947410583496,
    "generate_time": 0.08084511756896973,
    "total_time": 0.2530345916748047,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "tf.lite.TFLiteConverter",
    "context": [
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段"
      },
      {
        "content": "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段"
      }
    ]
  },
  {
    "id": "q11",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 的 GPU 委托在 Java 侧创建时使用的类名是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.1873462200164795,
    "generate_time": 0.07433676719665527,
    "total_time": 0.26168298721313477,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "GpuDelegate",
    "context": [
      {
        "content": "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段"
      },
      {
        "content": "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段"
      },
      {
        "content": "tfliteOptions.addDelegate(gpuDelegate);",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段"
      },
      {
        "content": "GpuDelegate delegate = new GpuDelegate();",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段"
      }
    ]
  },
  {
    "id": "q12",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 量化（quantization）主要带来哪两方面的好处？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.15184807777404785,
    "generate_time": 0.07087278366088867,
    "total_time": 0.22272086143493652,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "减少模型大小和提升推理性能",
    "context": [
      {
        "content": "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段"
      },
      {
        "content": "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段"
      }
    ]
  },
  {
    "id": "q13",
    "model": "baichuan2-13b-chat",
    "query": "示例中使用 ImageDataGenerator 加载数据时将 validation_split 设置为多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.16150927543640137,
    "generate_time": 1.616694688796997,
    "total_time": 1.7782039642333984,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "0.2（20% 用于验证集）",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段"
      },
      {
        "content": "validation_data=val_generator,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q14",
    "model": "baichuan2-13b-chat",
    "query": "在花卉识别示例中输入图像被缩放到的尺寸是多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.1792902946472168,
    "generate_time": 1.7597155570983887,
    "total_time": 1.9390058517456055,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "224×224",
    "context": [
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      },
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      }
    ]
  },
  {
    "id": "q15",
    "model": "baichuan2-13b-chat",
    "query": "该花卉识别应用最终需要识别多少种花？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.24923157691955566,
    "generate_time": 1.632558822631836,
    "total_time": 1.8817903995513916,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "四种花",
    "context": [
      {
        "content": "图8-6 花卉识别app",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段"
      },
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q16",
    "model": "baichuan2-13b-chat",
    "query": "Keras ImageDataGenerator 中用于按文件夹加载图像的函数是什么？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.1589655876159668,
    "generate_time": 1.8225092887878418,
    "total_time": 1.9814748764038086,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "flow_from_directory",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "Kirons提供了Image Data Generator类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s"
      },
      {
        "content": "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q17",
    "model": "baichuan2-13b-chat",
    "query": "示例中训练时的 batch_size 被设置为多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.23967981338500977,
    "generate_time": 1.6115939617156982,
    "total_time": 1.851273775100708,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "64",
    "context": [
      {
        "content": "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段"
      },
      {
        "content": "BatchSize 默认为32",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段"
      }
    ]
  },
  {
    "id": "q18",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 模型文件的默认扩展名是什么？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.18398547172546387,
    "generate_time": 1.6844077110290527,
    "total_time": 1.8683931827545166,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": ".tflite",
    "context": [
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "return \"model.tflite\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      }
    ]
  },
  {
    "id": "q19",
    "model": "baichuan2-13b-chat",
    "query": "Python 示例中使用哪行代码将量化优化应用于转换器？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.2681879997253418,
    "generate_time": 1.5310008525848389,
    "total_time": 1.7991888523101807,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "context": [
      {
        "content": "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "tflite_quant_model = converter.convert()",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段"
      },
      {
        "content": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段"
      }
    ]
  },
  {
    "id": "q20",
    "model": "baichuan2-13b-chat",
    "query": "描述 TensorFlow Lite 模型格式的 schema 文件名是什么？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.15789532661437988,
    "generate_time": 1.4784622192382812,
    "total_time": 1.6363575458526611,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "schema.fbs",
    "context": [
      {
        "content": "图8-2 TFLite schema.fbs样例代码",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段"
      },
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      }
    ]
  },
  {
    "id": "q1",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 主要面向哪三类设备进行模型部署？",
    "answer": "TensorFlow Lite 主要面向移动设备（mobile）、嵌入式设备（embedded）和物联网设备（IoT）进行模型部署。",
    "retrieve_time": 0.3072373867034912,
    "generate_time": 2.010296583175659,
    "total_time": 2.3175339698791504,
    "tokens_out": 32,
    "tokens_in": 340,
    "ground_truth": "移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）",
    "context": [
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      }
    ]
  },
  {
    "id": "q2",
    "model": "yi-34b-chat",
    "query": "全球约有多少台设备部署了 TensorFlow Lite？",
    "answer": "全球有超过40亿台设备部署了 TensorFlow Lite。",
    "retrieve_time": 0.16660022735595703,
    "generate_time": 1.5452980995178223,
    "total_time": 1.7118983268737793,
    "tokens_out": 17,
    "tokens_in": 349,
    "ground_truth": "超过 40 亿台设备",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "全球有超过40亿的设备上部署的TFLight",
        "source": "1112_222613.mp4 309.8-314.6s"
      }
    ]
  },
  {
    "id": "q3",
    "model": "yi-34b-chat",
    "query": "示例花卉分类项目优化并部署的核心模型是什么？",
    "answer": "示例花卉分类项目优化并部署的核心模型是MobileNet V2。",
    "retrieve_time": 0.24846124649047852,
    "generate_time": 1.3177595138549805,
    "total_time": 1.566220760345459,
    "tokens_out": 18,
    "tokens_in": 277,
    "ground_truth": "MobileNet（MobileNet V2）",
    "context": [
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段"
      },
      {
        "content": "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q4",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 的两大核心组件是什么？",
    "answer": "TensorFlow Lite 的两大核心组件是：\n\n1. TensorFlow Lite 解释器\n2. TensorFlow Lite 转换器\n\n这些组件共同支持在移动设备和嵌入式设备上运行机器学习模型。",
    "retrieve_time": 0.18504619598388672,
    "generate_time": 2.3058059215545654,
    "total_time": 2.490852117538452,
    "tokens_out": 54,
    "tokens_in": 146,
    "ground_truth": "Converter（转换器）和 Interpreter（解释器）",
    "context": [
      {
        "content": "TensorFlow Lite 包括两个主要组件：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      },
      {
        "content": "8.2.1 TensorFlow Lite整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段"
      }
    ]
  },
  {
    "id": "q5",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 使用哪种序列化格式存储模型文件？",
    "answer": "TensorFlow Lite 使用 FlatBuffers 序列化格式存储模型文件。",
    "retrieve_time": 0.4016439914703369,
    "generate_time": 1.376197338104248,
    "total_time": 1.777841329574585,
    "tokens_out": 18,
    "tokens_in": 332,
    "ground_truth": "FlatBuffers",
    "context": [
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段"
      },
      {
        "content": "8.2 TensorFlow Lite体系结构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段"
      }
    ]
  },
  {
    "id": "q6",
    "model": "yi-34b-chat",
    "query": "Google 在 2017 年底发布了哪款专为移动端设计的深度学习工具？",
    "answer": "Google 在 2017 年底发布了 TensorFlow Lite，这是一款专为移动端设计的深度学习工具。",
    "retrieve_time": 0.5203840732574463,
    "generate_time": 1.765120029449463,
    "total_time": 2.285504102706909,
    "tokens_out": 28,
    "tokens_in": 409,
    "ground_truth": "TensorFlow Lite",
    "context": [
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
        "source": "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s"
      },
      {
        "content": "Google开始了TF Mobile项目",
        "source": "1112_222613.mp4 145.9-149.4s"
      },
      {
        "content": "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段"
      }
    ]
  },
  {
    "id": "q7",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为多少？",
    "answer": "根据提供的参考资料，TensorFlow Lite 典型 ARM 32 位构建的二进制大小约为 1 MB。如果仅使用支持常见图像分类模型所需的运算符，大小则不到 300 KB。\n\n回答: 约为 1 MB，特定情况下不到 300 KB。",
    "retrieve_time": 0.1674821376800537,
    "generate_time": 2.507490873336792,
    "total_time": 2.6749730110168457,
    "tokens_out": 70,
    "tokens_in": 360,
    "ground_truth": "约 1 MB（仅常用算子时小于 300 KB）",
    "context": [
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q8",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 可以利用 Android 系统提供的哪项 API 进行硬件加速？",
    "answer": "TensorFlow Lite 可以利用 Android 系统提供的 Android 神经网络 API（Android NN API）进行硬件加速。",
    "retrieve_time": 0.16765975952148438,
    "generate_time": 1.8542985916137695,
    "total_time": 2.021958351135254,
    "tokens_out": 27,
    "tokens_in": 254,
    "ground_truth": "Android NN API（Android 神经网络 API）",
    "context": [
      {
        "content": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      }
    ]
  },
  {
    "id": "q9",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 模型转换的命令行工具名称是什么？",
    "answer": "TensorFlow Lite 模型转换的命令行工具名称是 **tflite_convert**。",
    "retrieve_time": 0.18008041381835938,
    "generate_time": 1.28537917137146,
    "total_time": 1.4654595851898193,
    "tokens_out": 21,
    "tokens_in": 165,
    "ground_truth": "tflite_convert",
    "context": [
      {
        "content": "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段"
      },
      {
        "content": "掌握TensorFlow Lite转换器作用",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段"
      },
      {
        "content": "TensorFlow Lite 转换器(Converter)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段"
      },
      {
        "content": "使用TFLite转换器转换模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段"
      }
    ]
  },
  {
    "id": "q10",
    "model": "yi-34b-chat",
    "query": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？",
    "answer": "在 Python 中将 SavedModel 转换为 TFLite 模型应使用 `tf.lite.TFLiteConverter` 类，并调用其 `from_saved_model()` 方法。\n\n示例代码：\n```python\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n```\n\n其中 `saved_model_dir` 是 SavedModel 文件目录的路径。",
    "retrieve_time": 0.17165040969848633,
    "generate_time": 3.4190566539764404,
    "total_time": 3.5907070636749268,
    "tokens_out": 103,
    "tokens_in": 238,
    "ground_truth": "tf.lite.TFLiteConverter",
    "context": [
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段"
      },
      {
        "content": "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段"
      },
      {
        "content": "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段"
      }
    ]
  },
  {
    "id": "q11",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 的 GPU 委托在 Java 侧创建时使用的类名是什么？",
    "answer": "GpuDelegate",
    "retrieve_time": 0.18283700942993164,
    "generate_time": 1.224517583847046,
    "total_time": 1.4073545932769775,
    "tokens_out": 5,
    "tokens_in": 221,
    "ground_truth": "GpuDelegate",
    "context": [
      {
        "content": "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段"
      },
      {
        "content": "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段"
      },
      {
        "content": "tfliteOptions.addDelegate(gpuDelegate);",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段"
      },
      {
        "content": "GpuDelegate delegate = new GpuDelegate();",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段"
      }
    ]
  },
  {
    "id": "q12",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 量化（quantization）主要带来哪两方面的好处？",
    "answer": "TensorFlow Lite 量化主要带来以下两方面的好处：\n\n1. **降低存储**：量化通过减少权重和激活值的精确表示，从而降低模型的大小。\n2. **减少计算量**：量化可以减少计算量，从而提高模型的执行效率，尤其是在资源受限的设备上。\n\n这些好处使得量化模型更适合在移动设备和嵌入式设备上运行。",
    "retrieve_time": 0.16086244583129883,
    "generate_time": 2.7525625228881836,
    "total_time": 2.9134249687194824,
    "tokens_out": 90,
    "tokens_in": 226,
    "ground_truth": "减少模型大小和提升推理性能",
    "context": [
      {
        "content": "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段"
      },
      {
        "content": "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段"
      }
    ]
  },
  {
    "id": "q13",
    "model": "yi-34b-chat",
    "query": "示例中使用 ImageDataGenerator 加载数据时将 validation_split 设置为多少？",
    "answer": "根据提供的参考资料，没有明确提到示例中将 `validation_subset` 设置为多少。资料中讨论了使用 `ImageDataGenerator` 和 `flow_from_directory()` 函数加载数据，并提到了验证集的相关内容，但没有具体说明 `validation_subset` 的数值设置。因此，无法从资料中确定 `validation_subset` 的具体值。\n\n回答: 不知道。",
    "retrieve_time": 0.16623282432556152,
    "generate_time": 2.771630048751831,
    "total_time": 2.9378628730773926,
    "tokens_out": 90,
    "tokens_in": 306,
    "ground_truth": "0.2（20% 用于验证集）",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段"
      },
      {
        "content": "validation_data=val_generator,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q14",
    "model": "yi-34b-chat",
    "query": "在花卉识别示例中输入图像被缩放到的尺寸是多少？",
    "answer": "参考提供的资料中并没有提及输入图像被缩放的具体尺寸。因此，我不知道输入图像被缩放到的具体尺寸。",
    "retrieve_time": 0.17168784141540527,
    "generate_time": 1.4901528358459473,
    "total_time": 1.6618406772613525,
    "tokens_out": 27,
    "tokens_in": 165,
    "ground_truth": "224×224",
    "context": [
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      },
      {
        "content": "通过迁移学习实现花卉识别模型",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      }
    ]
  },
  {
    "id": "q15",
    "model": "yi-34b-chat",
    "query": "该花卉识别应用最终需要识别多少种花？",
    "answer": "根据提供的资料，并没有具体说明该花卉识别应用最终需要识别多少种花。因此，我无法确定需要识别的花卉种类数量。",
    "retrieve_time": 0.17819786071777344,
    "generate_time": 1.5328760147094727,
    "total_time": 1.711073875427246,
    "tokens_out": 33,
    "tokens_in": 164,
    "ground_truth": "四种花",
    "context": [
      {
        "content": "图8-6 花卉识别app",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段"
      },
      {
        "content": "8.4 任务2：实现花卉识别",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段"
      },
      {
        "content": "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段"
      },
      {
        "content": "第一步通过天意学习实现花会识别模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s"
      }
    ]
  },
  {
    "id": "q16",
    "model": "yi-34b-chat",
    "query": "Keras ImageDataGenerator 中用于按文件夹加载图像的函数是什么？",
    "answer": "Keras **ImageDataGenerator** 中用于按文件夹加载图像的函数是 **flow_from_directory**。\n\n```python\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator()\ngenerator = datagen.flow_from_directory(directory, target_size, ...)\n```\n\n该函数会从指定目录中加载图像，并自动将其分为不同的类（基于子文件夹的名称）。",
    "retrieve_time": 0.17434263229370117,
    "generate_time": 3.094755172729492,
    "total_time": 3.2690978050231934,
    "tokens_out": 99,
    "tokens_in": 229,
    "ground_truth": "flow_from_directory",
    "context": [
      {
        "content": "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段"
      },
      {
        "content": "Kirons提供了Image Data Generator类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s"
      },
      {
        "content": "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段"
      },
      {
        "content": "Image Data Generator的构造罕述",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s"
      }
    ]
  },
  {
    "id": "q17",
    "model": "yi-34b-chat",
    "query": "示例中训练时的 batch_size 被设置为多少？",
    "answer": "示例中训练时的 batch_size 被设置为 64。",
    "retrieve_time": 0.15625977516174316,
    "generate_time": 1.2967939376831055,
    "total_time": 1.4530537128448486,
    "tokens_out": 17,
    "tokens_in": 195,
    "ground_truth": "64",
    "context": [
      {
        "content": "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段"
      },
      {
        "content": "BatchSize 默认为32",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段"
      },
      {
        "content": "batch_size=BATCH_SIZE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段"
      }
    ]
  },
  {
    "id": "q18",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 模型文件的默认扩展名是什么？",
    "answer": "TensorFlow Lite 模型文件的默认扩展名是 .tflite。",
    "retrieve_time": 0.14049720764160156,
    "generate_time": 1.612445592880249,
    "total_time": 1.7529428005218506,
    "tokens_out": 18,
    "tokens_in": 286,
    "ground_truth": ".tflite",
    "context": [
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "return \"model.tflite\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      },
      {
        "content": "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段"
      }
    ]
  },
  {
    "id": "q19",
    "model": "yi-34b-chat",
    "query": "Python 示例中使用哪行代码将量化优化应用于转换器？",
    "answer": "根据提供的资料，量化优化通过以下代码行应用于转换器：\n\n```python\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n```\n\n这行代码设置了优化选项以减小模型大小，从而实现量化。",
    "retrieve_time": 0.1658947467803955,
    "generate_time": 2.650733470916748,
    "total_time": 2.8166282176971436,
    "tokens_out": 65,
    "tokens_in": 209,
    "ground_truth": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "context": [
      {
        "content": "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段"
      },
      {
        "content": "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段"
      },
      {
        "content": "tflite_quant_model = converter.convert()",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段"
      },
      {
        "content": "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段"
      }
    ]
  },
  {
    "id": "q20",
    "model": "yi-34b-chat",
    "query": "描述 TensorFlow Lite 模型格式的 schema 文件名是什么？",
    "answer": "TensorFlow Lite 模型格式的 schema 文件名是 **schema.fbs**。",
    "retrieve_time": 0.16457009315490723,
    "generate_time": 1.5515129566192627,
    "total_time": 1.71608304977417,
    "tokens_out": 21,
    "tokens_in": 291,
    "ground_truth": "schema.fbs",
    "context": [
      {
        "content": "图8-2 TFLite schema.fbs样例代码",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段"
      },
      {
        "content": "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段"
      },
      {
        "content": "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段"
      },
      {
        "content": "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段"
      }
    ]
  }
]