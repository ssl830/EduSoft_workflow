[
  {
    "id": "q21",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 项目的技能目标中提到需要熟练使用哪款 IDE？",
    "answer": "根据提供的参考资料，没有提及TensorFlow Lite项目需要熟练使用哪款IDE（集成开发环境）的具体信息。因此，我无法回答这个问题。",
    "retrieve_time": 0.3531837463378906,
    "generate_time": 5.294549465179443,
    "total_time": 5.647733211517334,
    "tokens_out": 31,
    "tokens_in": 157,
    "ground_truth": "Android Studio",
    "context": [
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "项目8 TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q22",
    "model": "deepseek-v3",
    "query": "TensorFlow 生态中用于高性能服务器端部署的平台叫什么？",
    "answer": "TensorFlow生态中用于高性能服务器端部署的平台是 **TensorFlow Serving**。",
    "retrieve_time": 0.26180291175842285,
    "generate_time": 6.226293087005615,
    "total_time": 6.488095998764038,
    "tokens_out": 17,
    "tokens_in": 378,
    "ground_truth": "TensorFlow Serving",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q23",
    "model": "deepseek-v3",
    "query": "哪家公司被提及使用 TensorFlow Lite 进行 OCR 处理？",
    "answer": "网易被提及使用 TensorFlow Lite 进行 OCR 处理。",
    "retrieve_time": 0.2831864356994629,
    "generate_time": 4.475634336471558,
    "total_time": 4.7588207721710205,
    "tokens_out": 13,
    "tokens_in": 347,
    "ground_truth": "网易",
    "context": [
      {
        "content": "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q24",
    "model": "deepseek-v3",
    "query": "在 32 位安卓平台，仅核心运行时代码大小约为多少 KB？",
    "answer": "在32位安卓平台下，仅核心运行时代码大小约为100 KB左右（参考资料1）。",
    "retrieve_time": 0.1686699390411377,
    "generate_time": 4.299377918243408,
    "total_time": 4.468047857284546,
    "tokens_out": 21,
    "tokens_in": 277,
    "ground_truth": "约 100 KB",
    "context": [
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段"
      }
    ]
  },
  {
    "id": "q25",
    "model": "deepseek-v3",
    "query": "TensorFlow Lite 工作流程的第四步强调了哪项操作？",
    "answer": "根据提供的参考资料，无法确定工作流程第四步的具体操作内容。资料中提到了图8-3展示了工作流程（内容1/3）以及开发流程的任务（内容2），但未明确描述步骤细节。建议查阅图8-3或完整文档以获取准确信息。",
    "retrieve_time": 0.16931605339050293,
    "generate_time": 6.23215913772583,
    "total_time": 6.401475191116333,
    "tokens_out": 59,
    "tokens_in": 133,
    "ground_truth": "优化模型（size/performance trade-off）",
    "context": [
      {
        "content": "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段"
      },
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "图8-3 TensorFlow Lite 的工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      }
    ]
  },
  {
    "id": "q26",
    "model": "deepseek-v3",
    "query": "训练集包含多少张花卉图片？",
    "answer": "根据参考资料2，该数据集中平均每一种花有734张图片。但参考资料未明确说明具体包含多少种花卉类别或训练集的总图片数量。因此无法确定训练集的具体图片总数。",
    "retrieve_time": 0.35719895362854004,
    "generate_time": 5.798173189163208,
    "total_time": 6.155372142791748,
    "tokens_out": 42,
    "tokens_in": 164,
    "ground_truth": "2939 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "fname=\"flower_photos.tgz\",",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段"
      }
    ]
  },
  {
    "id": "q27",
    "model": "deepseek-v3",
    "query": "验证集包含多少张花卉图片？",
    "answer": "根据参考资料3，花会数据集中平均每种花有734张图片，但未明确提及验证集的具体图片数量。因此无法直接回答验证集包含多少张花卉图片。",
    "retrieve_time": 0.24943923950195312,
    "generate_time": 5.468899488449097,
    "total_time": 5.71833872795105,
    "tokens_out": 38,
    "tokens_in": 164,
    "ground_truth": "731 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      }
    ]
  },
  {
    "id": "q28",
    "model": "deepseek-v3",
    "query": "示例代码中保存类别标签的文件名是什么？",
    "answer": "根据参考资料，保存类别标签的文件名是`labels.txt`（参考内容1和内容2）。",
    "retrieve_time": 0.45096373558044434,
    "generate_time": 4.141493082046509,
    "total_time": 4.592456817626953,
    "tokens_out": 21,
    "tokens_in": 116,
    "ground_truth": "labels.txt",
    "context": [
      {
        "content": "with open('labels.txt', 'w') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段"
      },
      {
        "content": "return \"labels.txt\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段"
      },
      {
        "content": "默认是将图片分类到1000类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      }
    ]
  },
  {
    "id": "q29",
    "model": "deepseek-v3",
    "query": "MobileNet V2 基础模型的输入形状 IMG_SHAPE 被设置为多少？",
    "answer": "根据参考资料内容2，`MobileNetV2`的输入形状是通过参数`input_shape=IMG_SHAPE`指定的，但提供的资料中并未明确说明`IMG_SHAPE`的具体数值。因此，无法从给定资料中确定其具体设置值。",
    "retrieve_time": 0.16535091400146484,
    "generate_time": 5.816066026687622,
    "total_time": 5.981416940689087,
    "tokens_out": 54,
    "tokens_in": 186,
    "ground_truth": "(224, 224, 3)",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      }
    ]
  },
  {
    "id": "q30",
    "model": "deepseek-v3",
    "query": "为何在实例化 MobileNet V2 时将 include_top 参数设为 False？",
    "answer": "将 `include_top` 参数设为 `False` 是为了移除 MobileNet V2 模型默认的顶层（即原始的1000类分类输出层），从而适配自定义的分类任务（例如用户案例中的5类分类）。这样可以在预训练模型的基础上，替换为新的输出层（如全连接层）以适应特定的分类需求。",
    "retrieve_time": 0.25536513328552246,
    "generate_time": 6.174283266067505,
    "total_time": 6.429648399353027,
    "tokens_out": 70,
    "tokens_in": 223,
    "ground_truth": "去除原有 1000 类分类头，以便添加自定义输出层",
    "context": [
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "使用少量顶层而不是整个MobileNet模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      },
      {
        "content": "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段"
      }
    ]
  },
  {
    "id": "q31",
    "model": "deepseek-v3",
    "query": "将 base_model.trainable 设为 False 的目的是什么？",
    "answer": "将 `base_model.trainable` 设为 `False` 的目的是在迁移学习中冻结基础模型的参数，使其在训练过程中不会被更新。这样可以保留基础模型在大规模数据集上预训练得到的优势特征，同时只训练新添加的层（如分类器），以提高训练效率和模型性能。",
    "retrieve_time": 0.24666404724121094,
    "generate_time": 6.090632200241089,
    "total_time": 6.3372962474823,
    "tokens_out": 61,
    "tokens_in": 196,
    "ground_truth": "冻结预训练权重，避免在初始训练阶段被更新",
    "context": [
      {
        "content": "base_model.trainable = False",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "base_model.trainable = True",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      }
    ]
  },
  {
    "id": "q32",
    "model": "deepseek-v3",
    "query": "自定义网络最后一层使用的激活函数是什么？",
    "answer": "根据参考资料，自定义网络的最后一层是一个5个节点的输出层（内容2、内容3），但参考资料中未明确提及该层使用的激活函数类型。因此，无法从给定信息中确定其激活函数。\n\n回答：不知道。",
    "retrieve_time": 0.25780248641967773,
    "generate_time": 5.8007118701934814,
    "total_time": 6.058514356613159,
    "tokens_out": 49,
    "tokens_in": 208,
    "ground_truth": "softmax",
    "context": [
      {
        "content": "表示不需要远有模型中最后的神经网络层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s"
      },
      {
        "content": "最后是一个五个节点的输出层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s"
      },
      {
        "content": "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段"
      },
      {
        "content": "基础模型的最后几层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s"
      }
    ]
  },
  {
    "id": "q33",
    "model": "deepseek-v3",
    "query": "初始训练阶段采用的优化器是哪一个？",
    "answer": "初始训练阶段采用的优化器是 **Adam**，学习率设置为 **1e-5**（参考资料 3）。",
    "retrieve_time": 0.26912355422973633,
    "generate_time": 4.757384538650513,
    "total_time": 5.026508092880249,
    "tokens_out": 25,
    "tokens_in": 169,
    "ground_truth": "Adam",
    "context": [
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "在训练之前先编译模型，损失函数使用类别交叉熵。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段"
      },
      {
        "content": "optimizer = tf.keras.optimizers.Adam(1e-5),",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q34",
    "model": "deepseek-v3",
    "query": "模型中不可训练参数（Non-trainable params）的数量是多少？",
    "answer": "根据参考资料，模型中不可训练参数（Non-trainable params）的数量是 **2,257,984**（内容1）。这是由于采用了迁移学习策略（内容3），通过设置`model.trainable = False`冻结了基础模型的参数（内容4），保留了原始预训练模型的权重。",
    "retrieve_time": 0.25827622413635254,
    "generate_time": 6.182586669921875,
    "total_time": 6.4408628940582275,
    "tokens_out": 61,
    "tokens_in": 163,
    "ground_truth": "2,257,984",
    "context": [
      {
        "content": "Non-trainable params: 2,257,984",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段"
      },
      {
        "content": "Trainable params: 368,837",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q35",
    "model": "deepseek-v3",
    "query": "微调 (fine-tuning) 时从第几层开始解冻？",
    "answer": "根据参考资料，微调时应从指定层（`fine_tune_at`）开始解冻顶层，并冻结该层之前的所有层（内容2、3）。具体从第几层开始需根据模型结构和任务需求确定，但核心原则是：解冻顶层以调整高级特征（内容4），同时保持底层权重冻结。资料未提供具体层数编号，需结合实际模型配置决定。",
    "retrieve_time": 0.26157569885253906,
    "generate_time": 7.718105316162109,
    "total_time": 7.979681015014648,
    "tokens_out": 85,
    "tokens_in": 163,
    "ground_truth": "第 100 层 (fine_tune_at = 100) 之后",
    "context": [
      {
        "content": "首先取消冻结模型的顶层，代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段"
      },
      {
        "content": "# Fine tune from this layer onwards",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段"
      },
      {
        "content": "# Freeze all the layers before the `fine_tune_at` layer",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      }
    ]
  },
  {
    "id": "q36",
    "model": "deepseek-v3",
    "query": "MobileNet V2 基础模型总层数是多少？",
    "answer": "根据提供的参考资料，未明确提及MobileNet V2基础模型的总层数。因此，我无法基于当前资料给出准确答案。建议查阅官方文档或相关论文以获取具体层数信息。",
    "retrieve_time": 0.5278728008270264,
    "generate_time": 5.987133741378784,
    "total_time": 6.5150065422058105,
    "tokens_out": 42,
    "tokens_in": 170,
    "ground_truth": "155 层",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "我们选择MobileNet V2进行千亿学习",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s"
      }
    ]
  },
  {
    "id": "q37",
    "model": "deepseek-v3",
    "query": "微调阶段使用的学习率被设置为多少？",
    "answer": "根据提供的参考资料，没有提到微调阶段具体使用的学习率数值。因此，我无法回答这个问题。",
    "retrieve_time": 0.30161261558532715,
    "generate_time": 5.394592046737671,
    "total_time": 5.696204662322998,
    "tokens_out": 22,
    "tokens_in": 231,
    "ground_truth": "1e-5",
    "context": [
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      },
      {
        "content": "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段"
      }
    ]
  },
  {
    "id": "q38",
    "model": "deepseek-v3",
    "query": "微调后模型的验证精度大约达到多少？",
    "answer": "根据参考资料1，微调后模型的精度几乎达到98%。因此验证精度大约为98%。",
    "retrieve_time": 0.2712585926055908,
    "generate_time": 4.958947658538818,
    "total_time": 5.230206251144409,
    "tokens_out": 20,
    "tokens_in": 176,
    "ground_truth": "约 98%",
    "context": [
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "经过微调后",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      }
    ]
  },
  {
    "id": "q39",
    "model": "deepseek-v3",
    "query": "SavedModel 被保存到哪个目录？",
    "answer": "根据参考资料，SavedModel 被保存到由 `saved_model_dir` 参数指定的绝对路径目录中。该参数类型为字符串（string），需明确提供目标目录的完整路径。例如：`tf.saved_model.save(model, saved_model_dir)` 会将模型保存至 `saved_model_dir` 对应的路径下。",
    "retrieve_time": 0.13108325004577637,
    "generate_time": 7.035810708999634,
    "total_time": 7.16689395904541,
    "tokens_out": 71,
    "tokens_in": 165,
    "ground_truth": "save/fine_tuning",
    "context": [
      {
        "content": "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      },
      {
        "content": "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段"
      },
      {
        "content": "tf.saved_model.save(model, saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段"
      }
    ]
  },
  {
    "id": "q40",
    "model": "deepseek-v3",
    "query": "Android 项目中应将 model.tflite 放置到哪个 assets 路径？",
    "answer": "根据参考资料内容1，应将 `model.tflite` 文件放置到 Android 项目的以下路径中：  \n`/android/start/app/src/main/assets/`  \n\n同时需要确保标签文件 `label.txt` 也一并拷贝到该目录下。其他参考资料中的路径（如 `save/fine_tuning/assets/`）与标准 Android 项目结构无关，可忽略。",
    "retrieve_time": 0.276094913482666,
    "generate_time": 6.852003574371338,
    "total_time": 7.128098487854004,
    "tokens_out": 81,
    "tokens_in": 166,
    "ground_truth": "android/start/app/src/main/assets/",
    "context": [
      {
        "content": "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段"
      },
      {
        "content": "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段"
      }
    ]
  },
  {
    "id": "q21",
    "model": "qwen-max",
    "query": "TensorFlow Lite 项目的技能目标中提到需要熟练使用哪款 IDE？",
    "answer": "根据提供的参考资料，没有提到TensorFlow Lite项目中具体需要熟练使用的IDE。因此，对于这个问题，我没有足够的信息来给出答案。",
    "retrieve_time": 0.25449490547180176,
    "generate_time": 2.045074939727783,
    "total_time": 2.299569845199585,
    "tokens_out": 29,
    "tokens_in": 167,
    "ground_truth": "Android Studio",
    "context": [
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "项目8 TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q22",
    "model": "qwen-max",
    "query": "TensorFlow 生态中用于高性能服务器端部署的平台叫什么？",
    "answer": "TensorFlow 生态中用于高性能服务器端部署的平台叫做 TensorFlow Serving。",
    "retrieve_time": 0.1756293773651123,
    "generate_time": 1.3523409366607666,
    "total_time": 1.527970314025879,
    "tokens_out": 16,
    "tokens_in": 407,
    "ground_truth": "TensorFlow Serving",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q23",
    "model": "qwen-max",
    "query": "哪家公司被提及使用 TensorFlow Lite 进行 OCR 处理？",
    "answer": "根据提供的资料，网易被提及使用 TensorFlow Lite 进行OCR处理。",
    "retrieve_time": 0.18102550506591797,
    "generate_time": 1.1253259181976318,
    "total_time": 1.3063514232635498,
    "tokens_out": 16,
    "tokens_in": 363,
    "ground_truth": "网易",
    "context": [
      {
        "content": "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q24",
    "model": "qwen-max",
    "query": "在 32 位安卓平台，仅核心运行时代码大小约为多少 KB？",
    "answer": "在32位安卓平台下，仅核心运行时的代码大小约为100 KB。",
    "retrieve_time": 0.19641923904418945,
    "generate_time": 2.3517487049102783,
    "total_time": 2.5481679439544678,
    "tokens_out": 21,
    "tokens_in": 310,
    "ground_truth": "约 100 KB",
    "context": [
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段"
      }
    ]
  },
  {
    "id": "q25",
    "model": "qwen-max",
    "query": "TensorFlow Lite 工作流程的第四步强调了哪项操作？",
    "answer": "根据提供的参考资料，没有具体列出TensorFlow Lite工作流程的各个步骤。因此，我无法直接指出第四步强调了哪项操作。如果您能提供更多关于这些步骤的信息，我会很乐意帮助您进一步解答。",
    "retrieve_time": 0.1466212272644043,
    "generate_time": 2.9120519161224365,
    "total_time": 3.058673143386841,
    "tokens_out": 46,
    "tokens_in": 137,
    "ground_truth": "优化模型（size/performance trade-off）",
    "context": [
      {
        "content": "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段"
      },
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "图8-3 TensorFlow Lite 的工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      }
    ]
  },
  {
    "id": "q26",
    "model": "qwen-max",
    "query": "训练集包含多少张花卉图片？",
    "answer": "根据提供的资料，我们知道数据集里每种类别的花平均有734张图片。但是，资料中并没有直接说明总共有多少种类别的花。因此，基于现有信息，我无法给出训练集中总共包含多少张花卉图片的确切数字。如果你能提供更多关于花种类数量的信息，我可以帮助计算总数。",
    "retrieve_time": 0.19949078559875488,
    "generate_time": 5.274488925933838,
    "total_time": 5.473979711532593,
    "tokens_out": 69,
    "tokens_in": 176,
    "ground_truth": "2939 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "fname=\"flower_photos.tgz\",",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段"
      }
    ]
  },
  {
    "id": "q27",
    "model": "qwen-max",
    "query": "验证集包含多少张花卉图片？",
    "answer": "根据提供的参考资料，没有具体提到验证集中包含多少张花卉图片。资料中仅说明了平均每一种花有734张图片，但并未提及这些图片如何被划分为训练集、测试集或验证集。因此，关于验证集具体包含多少张图片的信息无法直接得出。如果需要更准确的数据划分信息，可能需要查阅更多关于数据集使用的细节或者默认的数据集分割规则。",
    "retrieve_time": 1.265110969543457,
    "generate_time": 6.741541147232056,
    "total_time": 8.006652116775513,
    "tokens_out": 87,
    "tokens_in": 178,
    "ground_truth": "731 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      }
    ]
  },
  {
    "id": "q28",
    "model": "qwen-max",
    "query": "示例代码中保存类别标签的文件名是什么？",
    "answer": "根据提供的参考资料，保存类别标签的文件名是`labels.txt`。这可以从内容1和内容2中推断出来，其中提到了对名为`labels.txt`的文件进行写操作，并且返回了同样的文件名字符串。",
    "retrieve_time": 0.25180816650390625,
    "generate_time": 3.8767013549804688,
    "total_time": 4.128509521484375,
    "tokens_out": 51,
    "tokens_in": 123,
    "ground_truth": "labels.txt",
    "context": [
      {
        "content": "with open('labels.txt', 'w') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段"
      },
      {
        "content": "return \"labels.txt\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段"
      },
      {
        "content": "默认是将图片分类到1000类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      }
    ]
  },
  {
    "id": "q29",
    "model": "qwen-max",
    "query": "MobileNet V2 基础模型的输入形状 IMG_SHAPE 被设置为多少？",
    "answer": "参考资料中并没有直接给出`IMG_SHAPE`的具体数值。通常，对于MobileNet V2模型，默认的输入形状是(224, 224, 3)，这意味着图片的高度和宽度都是224像素，并且图像是RGB格式（即3个颜色通道）。但是，根据您的具体应用场景或需求，`IMG_SHAPE`可以被设置为其他值。若要获取确切的`IMG_SHAPE`值，请参考您所使用的代码或文档中的具体设定。",
    "retrieve_time": 0.16957330703735352,
    "generate_time": 8.624725818634033,
    "total_time": 8.794299125671387,
    "tokens_out": 103,
    "tokens_in": 198,
    "ground_truth": "(224, 224, 3)",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      }
    ]
  },
  {
    "id": "q30",
    "model": "qwen-max",
    "query": "为何在实例化 MobileNet V2 时将 include_top 参数设为 False？",
    "answer": "在实例化MobileNet V2时将`include_top`参数设为`False`，是因为默认情况下该模型是设计来分类图片到1000个类别（基于ImageNet数据集）。当你的任务只需要将图片分类到较少的类别（例如这里的5类）时，设置`include_top=False`可以移除模型最后用于1000分类的全连接层。这样做的好处是可以让你根据特定需求自定义模型的最后一部分，比如添加适合自己任务的新输出层，从而使得模型能够更好地适应具体的应用场景。",
    "retrieve_time": 0.2508268356323242,
    "generate_time": 10.454517841339111,
    "total_time": 10.705344676971436,
    "tokens_out": 117,
    "tokens_in": 243,
    "ground_truth": "去除原有 1000 类分类头，以便添加自定义输出层",
    "context": [
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "使用少量顶层而不是整个MobileNet模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      },
      {
        "content": "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段"
      }
    ]
  },
  {
    "id": "q31",
    "model": "qwen-max",
    "query": "将 base_model.trainable 设为 False 的目的是什么？",
    "answer": "将 `base_model.trainable` 设为 `False` 的目的是在进行迁移学习时，保持基础模型（如预训练的网络）原有的参数不变。这样做可以保留该模型通过大规模数据集训练获得的优势与特征提取能力，同时允许我们在其基础上（通常是顶部）添加新的层，并仅针对这些新层以及可能的部分顶层进行训练和微调。这有助于更高效地利用现有资源来改进特定任务的表现，而无需从头开始训练整个模型。",
    "retrieve_time": 0.2357015609741211,
    "generate_time": 8.742478609085083,
    "total_time": 8.978180170059204,
    "tokens_out": 102,
    "tokens_in": 210,
    "ground_truth": "冻结预训练权重，避免在初始训练阶段被更新",
    "context": [
      {
        "content": "base_model.trainable = False",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "base_model.trainable = True",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      }
    ]
  },
  {
    "id": "q32",
    "model": "qwen-max",
    "query": "自定义网络最后一层使用的激活函数是什么？",
    "answer": "根据提供的参考资料，没有明确提到自定义网络最后一层具体使用了哪种激活函数。因此，对于您的问题“自定义网络最后一层使用的激活函数是什么？”我无法直接给出答案，因为资料中缺少关于最后一层激活函数的具体信息。在实际应用中，这通常取决于问题的性质（比如分类任务可能会使用softmax作为输出层的激活函数），但是基于给定的信息，我们不能确定这里的情况。如果您有更多上下文或特定要求，请提供进一步的信息。",
    "retrieve_time": 0.24581336975097656,
    "generate_time": 7.9626288414001465,
    "total_time": 8.208442211151123,
    "tokens_out": 103,
    "tokens_in": 221,
    "ground_truth": "softmax",
    "context": [
      {
        "content": "表示不需要远有模型中最后的神经网络层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s"
      },
      {
        "content": "最后是一个五个节点的输出层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s"
      },
      {
        "content": "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段"
      },
      {
        "content": "基础模型的最后几层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s"
      }
    ]
  },
  {
    "id": "q33",
    "model": "qwen-max",
    "query": "初始训练阶段采用的优化器是哪一个？",
    "answer": "初始训练阶段采用的优化器是`tf.keras.optimizers.Adam`，其学习率设定为1e-5。",
    "retrieve_time": 0.2218787670135498,
    "generate_time": 1.9131410121917725,
    "total_time": 2.1350197792053223,
    "tokens_out": 26,
    "tokens_in": 175,
    "ground_truth": "Adam",
    "context": [
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "在训练之前先编译模型，损失函数使用类别交叉熵。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段"
      },
      {
        "content": "optimizer = tf.keras.optimizers.Adam(1e-5),",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q34",
    "model": "qwen-max",
    "query": "模型中不可训练参数（Non-trainable params）的数量是多少？",
    "answer": "模型中不可训练参数（Non-trainable params）的数量是2,257,984。",
    "retrieve_time": 0.17612695693969727,
    "generate_time": 2.3200581073760986,
    "total_time": 2.496185064315796,
    "tokens_out": 24,
    "tokens_in": 181,
    "ground_truth": "2,257,984",
    "context": [
      {
        "content": "Non-trainable params: 2,257,984",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段"
      },
      {
        "content": "Trainable params: 368,837",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q35",
    "model": "qwen-max",
    "query": "微调 (fine-tuning) 时从第几层开始解冻？",
    "answer": "根据提供的资料，没有明确指出微调(fine-tuning)时具体从哪一层开始解冻。资料中提到“# Fine tune from this layer onwards”和“# Freeze all the layers before the `fine_tune_at` layer”，这表明存在一个特定的层（用`fine_tune_at`表示），从这个层开始之后的所有层将被设置为可训练状态以进行微调，而该层之前的所有层则保持冻结状态。但是具体的层数或`fine_tune_at`的确切值没有给出。因此，无法直接回答微调应该从第几层开始解冻的问题。实际操作中，`fine_tune_at`的具体值需要根据所使用的模型及应用场景来确定。",
    "retrieve_time": 0.17021441459655762,
    "generate_time": 15.796079158782959,
    "total_time": 15.966293573379517,
    "tokens_out": 155,
    "tokens_in": 176,
    "ground_truth": "第 100 层 (fine_tune_at = 100) 之后",
    "context": [
      {
        "content": "首先取消冻结模型的顶层，代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段"
      },
      {
        "content": "# Fine tune from this layer onwards",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段"
      },
      {
        "content": "# Freeze all the layers before the `fine_tune_at` layer",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      }
    ]
  },
  {
    "id": "q36",
    "model": "qwen-max",
    "query": "MobileNet V2 基础模型总层数是多少？",
    "answer": "根据提供的参考资料，没有直接提到MobileNet V2基础模型的具体层数信息。因此，对于您问的“MobileNet V2 基础模型总层数是多少？”这个问题，基于给定的信息我无法给出确切答案。如果您需要这个具体数字，可能需要查阅更详细的MobileNet V2架构文档或相关研究论文。",
    "retrieve_time": 0.25746631622314453,
    "generate_time": 4.067902326583862,
    "total_time": 4.325368642807007,
    "tokens_out": 73,
    "tokens_in": 184,
    "ground_truth": "155 层",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "我们选择MobileNet V2进行千亿学习",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s"
      }
    ]
  },
  {
    "id": "q37",
    "model": "qwen-max",
    "query": "微调阶段使用的学习率被设置为多少？",
    "answer": "参考资料中没有提到微调阶段具体使用的学习率是多少。因此，根据提供的信息，我无法给出确切的答案。如果您有更具体的上下文或额外的信息来源，可能会有助于找到答案。",
    "retrieve_time": 0.1675126552581787,
    "generate_time": 3.003673791885376,
    "total_time": 3.1711864471435547,
    "tokens_out": 41,
    "tokens_in": 250,
    "ground_truth": "1e-5",
    "context": [
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      },
      {
        "content": "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段"
      }
    ]
  },
  {
    "id": "q38",
    "model": "qwen-max",
    "query": "微调后模型的验证精度大约达到多少？",
    "answer": "根据提供的参考资料，微调后模型的精度几乎达到了98%。但请注意，这个数值是针对特定情况下的结果，实际应用中可能会有所不同。",
    "retrieve_time": 0.17942404747009277,
    "generate_time": 2.9130895137786865,
    "total_time": 3.0925135612487793,
    "tokens_out": 34,
    "tokens_in": 192,
    "ground_truth": "约 98%",
    "context": [
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "经过微调后",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      }
    ]
  },
  {
    "id": "q39",
    "model": "qwen-max",
    "query": "SavedModel 被保存到哪个目录？",
    "answer": "SavedModel 会被保存到通过 `tf.saved_model.save` 函数中指定的目录，该目录由参数 `saved_model_dir` 来定义。这个参数需要是一个字符串，指定了含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。因此，具体是哪个目录取决于您在调用 `tf.saved_model.save` 函数时为 `saved_model_dir` 参数提供的值。",
    "retrieve_time": 0.1701369285583496,
    "generate_time": 6.174994945526123,
    "total_time": 6.345131874084473,
    "tokens_out": 93,
    "tokens_in": 170,
    "ground_truth": "save/fine_tuning",
    "context": [
      {
        "content": "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      },
      {
        "content": "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段"
      },
      {
        "content": "tf.saved_model.save(model, saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段"
      }
    ]
  },
  {
    "id": "q40",
    "model": "qwen-max",
    "query": "Android 项目中应将 model.tflite 放置到哪个 assets 路径？",
    "answer": "在Android项目中，应将`model.tflite`文件放置到`/android/start/app/src/main/assets/`路径下。这是根据提供的参考资料内容1直接指出的存放位置。",
    "retrieve_time": 0.25397801399230957,
    "generate_time": 2.59151029586792,
    "total_time": 2.8454883098602295,
    "tokens_out": 41,
    "tokens_in": 178,
    "ground_truth": "android/start/app/src/main/assets/",
    "context": [
      {
        "content": "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段"
      },
      {
        "content": "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段"
      }
    ]
  },
  {
    "id": "q21",
    "model": "glm-4",
    "query": "TensorFlow Lite 项目的技能目标中提到需要熟练使用哪款 IDE？",
    "answer": "不知道。参考资料中没有提到 TensorFlow Lite 项目的技能目标中需要熟练使用哪款 IDE。",
    "retrieve_time": 0.2814030647277832,
    "generate_time": 1.1090443134307861,
    "total_time": 1.3904473781585693,
    "tokens_out": 21,
    "tokens_in": 157,
    "ground_truth": "Android Studio",
    "context": [
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "项目8 TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q22",
    "model": "glm-4",
    "query": "TensorFlow 生态中用于高性能服务器端部署的平台叫什么？",
    "answer": "TensorFlow Serving。",
    "retrieve_time": 0.1616361141204834,
    "generate_time": 0.7514598369598389,
    "total_time": 0.9130959510803223,
    "tokens_out": 6,
    "tokens_in": 380,
    "ground_truth": "TensorFlow Serving",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q23",
    "model": "glm-4",
    "query": "哪家公司被提及使用 TensorFlow Lite 进行 OCR 处理？",
    "answer": "网易。",
    "retrieve_time": 0.19206571578979492,
    "generate_time": 0.5853583812713623,
    "total_time": 0.7774240970611572,
    "tokens_out": 4,
    "tokens_in": 342,
    "ground_truth": "网易",
    "context": [
      {
        "content": "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q24",
    "model": "glm-4",
    "query": "在 32 位安卓平台，仅核心运行时代码大小约为多少 KB？",
    "answer": "在32位安卓平台，仅核心运行时代码大小约为100 KB左右。",
    "retrieve_time": 0.16783690452575684,
    "generate_time": 1.1269307136535645,
    "total_time": 1.2947676181793213,
    "tokens_out": 19,
    "tokens_in": 280,
    "ground_truth": "约 100 KB",
    "context": [
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段"
      }
    ]
  },
  {
    "id": "q25",
    "model": "glm-4",
    "query": "TensorFlow Lite 工作流程的第四步强调了哪项操作？",
    "answer": "不知道\n\n由于提供的参考资料没有具体说明 TensorFlow Lite 工作流程的各步骤内容，无法确定第四步强调的是哪项操作。",
    "retrieve_time": 0.1782238483428955,
    "generate_time": 1.2072043418884277,
    "total_time": 1.3854281902313232,
    "tokens_out": 31,
    "tokens_in": 130,
    "ground_truth": "优化模型（size/performance trade-off）",
    "context": [
      {
        "content": "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段"
      },
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "图8-3 TensorFlow Lite 的工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      }
    ]
  },
  {
    "id": "q26",
    "model": "glm-4",
    "query": "训练集包含多少张花卉图片？",
    "answer": "根据提供的参考资料，每种花平均有734张图片，但是资料中没有提供具体有多少种花。因此，无法准确计算训练集中包含多少张花卉图片。如果假设有n种花，则总共大约有734n张图片。如果需要确切数字，请提供具体花的种类数。",
    "retrieve_time": 0.15605974197387695,
    "generate_time": 2.2580981254577637,
    "total_time": 2.4141578674316406,
    "tokens_out": 66,
    "tokens_in": 165,
    "ground_truth": "2939 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "fname=\"flower_photos.tgz\",",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段"
      }
    ]
  },
  {
    "id": "q27",
    "model": "glm-4",
    "query": "验证集包含多少张花卉图片？",
    "answer": "不知道。参考资料中没有提供关于验证集具体包含多少张花卉图片的信息。",
    "retrieve_time": 0.15435028076171875,
    "generate_time": 0.9118421077728271,
    "total_time": 1.066192388534546,
    "tokens_out": 18,
    "tokens_in": 167,
    "ground_truth": "731 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      }
    ]
  },
  {
    "id": "q28",
    "model": "glm-4",
    "query": "示例代码中保存类别标签的文件名是什么？",
    "answer": "根据提供的参考资料，示例代码中保存类别标签的文件名是 'labels.txt'。",
    "retrieve_time": 0.22248363494873047,
    "generate_time": 0.9238083362579346,
    "total_time": 1.146291971206665,
    "tokens_out": 21,
    "tokens_in": 118,
    "ground_truth": "labels.txt",
    "context": [
      {
        "content": "with open('labels.txt', 'w') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段"
      },
      {
        "content": "return \"labels.txt\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段"
      },
      {
        "content": "默认是将图片分类到1000类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      }
    ]
  },
  {
    "id": "q29",
    "model": "glm-4",
    "query": "MobileNet V2 基础模型的输入形状 IMG_SHAPE 被设置为多少？",
    "answer": "不知道。参考资料中未提供关于 `IMG_SHAPE` 的具体数值。",
    "retrieve_time": 0.15261220932006836,
    "generate_time": 0.823357105255127,
    "total_time": 0.9759693145751953,
    "tokens_out": 17,
    "tokens_in": 185,
    "ground_truth": "(224, 224, 3)",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      }
    ]
  },
  {
    "id": "q30",
    "model": "glm-4",
    "query": "为何在实例化 MobileNet V2 时将 include_top 参数设为 False？",
    "answer": "在实例化 MobileNet V2 时将 `include_top` 参数设为 False 是因为需要修改模型的结构以适应特定的分类任务。这样做可以去除模型原有的顶层神经网络层（即全连接层），这样用户可以添加自己的输出层，适应只有5类的分类任务，而不是默认的1000类。这有助于定制模型以适应不同的数据集和任务需求。",
    "retrieve_time": 0.1665647029876709,
    "generate_time": 3.0008723735809326,
    "total_time": 3.1674370765686035,
    "tokens_out": 80,
    "tokens_in": 225,
    "ground_truth": "去除原有 1000 类分类头，以便添加自定义输出层",
    "context": [
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "使用少量顶层而不是整个MobileNet模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      },
      {
        "content": "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段"
      }
    ]
  },
  {
    "id": "q31",
    "model": "glm-4",
    "query": "将 base_model.trainable 设为 False 的目的是什么？",
    "answer": "将 base_model.trainable 设为 False 的目的是为了在迁移学习中保留原始预训练模型的学习成果，防止在新的训练过程中基础模型的参数被修改，保持其在大规模数据集上训练获得的优势。这样可以只训练添加到基础模型上的新层或者分类器，而不改变原有模型的结构和参数。",
    "retrieve_time": 0.1506175994873047,
    "generate_time": 2.4497406482696533,
    "total_time": 2.600358247756958,
    "tokens_out": 68,
    "tokens_in": 197,
    "ground_truth": "冻结预训练权重，避免在初始训练阶段被更新",
    "context": [
      {
        "content": "base_model.trainable = False",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "base_model.trainable = True",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      }
    ]
  },
  {
    "id": "q32",
    "model": "glm-4",
    "query": "自定义网络最后一层使用的激活函数是什么？",
    "answer": "不知道\n\n根据提供的参考资料，没有明确说明自定义网络最后一层使用的激活函数是什么。通常情况下，输出层的激活函数会根据具体任务选择，例如分类任务可能会使用softmax激活函数，但此处未提供足够信息来确定所使用的激活函数。",
    "retrieve_time": 0.2363436222076416,
    "generate_time": 2.0757017135620117,
    "total_time": 2.3120453357696533,
    "tokens_out": 54,
    "tokens_in": 212,
    "ground_truth": "softmax",
    "context": [
      {
        "content": "表示不需要远有模型中最后的神经网络层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s"
      },
      {
        "content": "最后是一个五个节点的输出层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s"
      },
      {
        "content": "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段"
      },
      {
        "content": "基础模型的最后几层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s"
      }
    ]
  },
  {
    "id": "q33",
    "model": "glm-4",
    "query": "初始训练阶段采用的优化器是哪一个？",
    "answer": "初始训练阶段采用的优化器是 tf.keras.optimizers.Adam，其学习率设置为 1e-5。",
    "retrieve_time": 0.16775155067443848,
    "generate_time": 1.243379831314087,
    "total_time": 1.4111313819885254,
    "tokens_out": 25,
    "tokens_in": 167,
    "ground_truth": "Adam",
    "context": [
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "在训练之前先编译模型，损失函数使用类别交叉熵。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段"
      },
      {
        "content": "optimizer = tf.keras.optimizers.Adam(1e-5),",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q34",
    "model": "glm-4",
    "query": "模型中不可训练参数（Non-trainable params）的数量是多少？",
    "answer": "模型中不可训练参数（Non-trainable params）的数量是2,257,984。",
    "retrieve_time": 0.2101750373840332,
    "generate_time": 1.0285816192626953,
    "total_time": 1.2387566566467285,
    "tokens_out": 24,
    "tokens_in": 171,
    "ground_truth": "2,257,984",
    "context": [
      {
        "content": "Non-trainable params: 2,257,984",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段"
      },
      {
        "content": "Trainable params: 368,837",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q35",
    "model": "glm-4",
    "query": "微调 (fine-tuning) 时从第几层开始解冻？",
    "answer": "微调时从标记为 `fine_tune_at` 的层开始解冻。参考资料中没有提供具体的层数，但指出了“首先取消冻结模型的顶层”，这通常意味着从某个指定的层（在代码中通常由变量 `fine_tune_at` 表示）开始解冻。参考资料3也提到了“冻结所有在 `fine_tune_at` 层之前的层”。",
    "retrieve_time": 0.18607473373413086,
    "generate_time": 2.8759210109710693,
    "total_time": 3.0619957447052,
    "tokens_out": 82,
    "tokens_in": 166,
    "ground_truth": "第 100 层 (fine_tune_at = 100) 之后",
    "context": [
      {
        "content": "首先取消冻结模型的顶层，代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段"
      },
      {
        "content": "# Fine tune from this layer onwards",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段"
      },
      {
        "content": "# Freeze all the layers before the `fine_tune_at` layer",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      }
    ]
  },
  {
    "id": "q36",
    "model": "glm-4",
    "query": "MobileNet V2 基础模型总层数是多少？",
    "answer": "不知道。参考资料中没有提供MobileNet V2基础模型的总层数信息。",
    "retrieve_time": 0.15993475914001465,
    "generate_time": 0.8541998863220215,
    "total_time": 1.0141346454620361,
    "tokens_out": 18,
    "tokens_in": 173,
    "ground_truth": "155 层",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "我们选择MobileNet V2进行千亿学习",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s"
      }
    ]
  },
  {
    "id": "q37",
    "model": "glm-4",
    "query": "微调阶段使用的学习率被设置为多少？",
    "answer": "不知道。参考资料中没有提供关于微调阶段使用的学习率的信息。",
    "retrieve_time": 0.18302488327026367,
    "generate_time": 0.8356263637542725,
    "total_time": 1.0186512470245361,
    "tokens_out": 16,
    "tokens_in": 239,
    "ground_truth": "1e-5",
    "context": [
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      },
      {
        "content": "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段"
      }
    ]
  },
  {
    "id": "q38",
    "model": "glm-4",
    "query": "微调后模型的验证精度大约达到多少？",
    "answer": "根据提供的资料，微调后模型的验证精度几乎达到98%。",
    "retrieve_time": 0.1849195957183838,
    "generate_time": 0.8795990943908691,
    "total_time": 1.064518690109253,
    "tokens_out": 16,
    "tokens_in": 180,
    "ground_truth": "约 98%",
    "context": [
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "经过微调后",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      }
    ]
  },
  {
    "id": "q39",
    "model": "glm-4",
    "query": "SavedModel 被保存到哪个目录？",
    "answer": "SavedModel 被保存到 `saved_model_dir` 指定的目录中。该目录是用户通过参数传递给 `tf.saved_model.save()` 函数的绝对路径。",
    "retrieve_time": 0.19029927253723145,
    "generate_time": 2.726454496383667,
    "total_time": 2.9167537689208984,
    "tokens_out": 41,
    "tokens_in": 162,
    "ground_truth": "save/fine_tuning",
    "context": [
      {
        "content": "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      },
      {
        "content": "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段"
      },
      {
        "content": "tf.saved_model.save(model, saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段"
      }
    ]
  },
  {
    "id": "q40",
    "model": "glm-4",
    "query": "Android 项目中应将 model.tflite 放置到哪个 assets 路径？",
    "answer": "Android 项目中应将 model.tflite 文件放置到 `/android/start/app/src/main/assets/` 路径下。",
    "retrieve_time": 0.19758963584899902,
    "generate_time": 1.271463394165039,
    "total_time": 1.469053030014038,
    "tokens_out": 30,
    "tokens_in": 172,
    "ground_truth": "android/start/app/src/main/assets/",
    "context": [
      {
        "content": "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段"
      },
      {
        "content": "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段"
      }
    ]
  },
  {
    "id": "q21",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 项目的技能目标中提到需要熟练使用哪款 IDE？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.29126930236816406,
    "generate_time": 0.2453162670135498,
    "total_time": 0.5365855693817139,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "Android Studio",
    "context": [
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "项目8 TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q22",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow 生态中用于高性能服务器端部署的平台叫什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.213958740234375,
    "generate_time": 0.10996270179748535,
    "total_time": 0.32392144203186035,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "TensorFlow Serving",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q23",
    "model": "baichuan2-13b-chat",
    "query": "哪家公司被提及使用 TensorFlow Lite 进行 OCR 处理？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.18725037574768066,
    "generate_time": 0.11585617065429688,
    "total_time": 0.30310654640197754,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "网易",
    "context": [
      {
        "content": "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q24",
    "model": "baichuan2-13b-chat",
    "query": "在 32 位安卓平台，仅核心运行时代码大小约为多少 KB？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.19280481338500977,
    "generate_time": 0.09885144233703613,
    "total_time": 0.2916562557220459,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "约 100 KB",
    "context": [
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段"
      }
    ]
  },
  {
    "id": "q25",
    "model": "baichuan2-13b-chat",
    "query": "TensorFlow Lite 工作流程的第四步强调了哪项操作？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.17781949043273926,
    "generate_time": 0.09409141540527344,
    "total_time": 0.2719109058380127,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "优化模型（size/performance trade-off）",
    "context": [
      {
        "content": "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段"
      },
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "图8-3 TensorFlow Lite 的工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      }
    ]
  },
  {
    "id": "q26",
    "model": "baichuan2-13b-chat",
    "query": "训练集包含多少张花卉图片？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.17376327514648438,
    "generate_time": 0.10116863250732422,
    "total_time": 0.2749319076538086,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "2939 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "fname=\"flower_photos.tgz\",",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段"
      }
    ]
  },
  {
    "id": "q27",
    "model": "baichuan2-13b-chat",
    "query": "验证集包含多少张花卉图片？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.17712068557739258,
    "generate_time": 0.10058021545410156,
    "total_time": 0.27770090103149414,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "731 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      }
    ]
  },
  {
    "id": "q28",
    "model": "baichuan2-13b-chat",
    "query": "示例代码中保存类别标签的文件名是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.19219183921813965,
    "generate_time": 0.0929410457611084,
    "total_time": 0.28513288497924805,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "labels.txt",
    "context": [
      {
        "content": "with open('labels.txt', 'w') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段"
      },
      {
        "content": "return \"labels.txt\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段"
      },
      {
        "content": "默认是将图片分类到1000类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      }
    ]
  },
  {
    "id": "q29",
    "model": "baichuan2-13b-chat",
    "query": "MobileNet V2 基础模型的输入形状 IMG_SHAPE 被设置为多少？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.2192707061767578,
    "generate_time": 0.09196233749389648,
    "total_time": 0.3112330436706543,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "(224, 224, 3)",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      }
    ]
  },
  {
    "id": "q30",
    "model": "baichuan2-13b-chat",
    "query": "为何在实例化 MobileNet V2 时将 include_top 参数设为 False？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.19633984565734863,
    "generate_time": 0.09725761413574219,
    "total_time": 0.2935974597930908,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "去除原有 1000 类分类头，以便添加自定义输出层",
    "context": [
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "使用少量顶层而不是整个MobileNet模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      },
      {
        "content": "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段"
      }
    ]
  },
  {
    "id": "q31",
    "model": "baichuan2-13b-chat",
    "query": "将 base_model.trainable 设为 False 的目的是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.15273547172546387,
    "generate_time": 0.09091544151306152,
    "total_time": 0.2436509132385254,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "冻结预训练权重，避免在初始训练阶段被更新",
    "context": [
      {
        "content": "base_model.trainable = False",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "base_model.trainable = True",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      }
    ]
  },
  {
    "id": "q32",
    "model": "baichuan2-13b-chat",
    "query": "自定义网络最后一层使用的激活函数是什么？",
    "answer": "模型调用错误: Error code: 404 - {'error': {'code': 'model_not_found', 'param': None, 'type': 'invalid_request_error', 'message': 'The model `Baichuan2-13B-Chat` does not exist'}}",
    "retrieve_time": 0.1831803321838379,
    "generate_time": 0.0869295597076416,
    "total_time": 0.2701098918914795,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "softmax",
    "context": [
      {
        "content": "表示不需要远有模型中最后的神经网络层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s"
      },
      {
        "content": "最后是一个五个节点的输出层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s"
      },
      {
        "content": "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段"
      },
      {
        "content": "基础模型的最后几层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s"
      }
    ]
  },
  {
    "id": "q33",
    "model": "baichuan2-13b-chat",
    "query": "初始训练阶段采用的优化器是哪一个？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.17879486083984375,
    "generate_time": 1.712388515472412,
    "total_time": 1.8911833763122559,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "Adam",
    "context": [
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "在训练之前先编译模型，损失函数使用类别交叉熵。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段"
      },
      {
        "content": "optimizer = tf.keras.optimizers.Adam(1e-5),",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q34",
    "model": "baichuan2-13b-chat",
    "query": "模型中不可训练参数（Non-trainable params）的数量是多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.16443967819213867,
    "generate_time": 1.6272475719451904,
    "total_time": 1.791687250137329,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "2,257,984",
    "context": [
      {
        "content": "Non-trainable params: 2,257,984",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段"
      },
      {
        "content": "Trainable params: 368,837",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q35",
    "model": "baichuan2-13b-chat",
    "query": "微调 (fine-tuning) 时从第几层开始解冻？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.18918776512145996,
    "generate_time": 2.6469502449035645,
    "total_time": 2.8361380100250244,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "第 100 层 (fine_tune_at = 100) 之后",
    "context": [
      {
        "content": "首先取消冻结模型的顶层，代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段"
      },
      {
        "content": "# Fine tune from this layer onwards",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段"
      },
      {
        "content": "# Freeze all the layers before the `fine_tune_at` layer",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      }
    ]
  },
  {
    "id": "q36",
    "model": "baichuan2-13b-chat",
    "query": "MobileNet V2 基础模型总层数是多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.17341995239257812,
    "generate_time": 1.546386957168579,
    "total_time": 1.7198069095611572,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "155 层",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "我们选择MobileNet V2进行千亿学习",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s"
      }
    ]
  },
  {
    "id": "q37",
    "model": "baichuan2-13b-chat",
    "query": "微调阶段使用的学习率被设置为多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.18803834915161133,
    "generate_time": 1.4834306240081787,
    "total_time": 1.67146897315979,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "1e-5",
    "context": [
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      },
      {
        "content": "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段"
      }
    ]
  },
  {
    "id": "q38",
    "model": "baichuan2-13b-chat",
    "query": "微调后模型的验证精度大约达到多少？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.216627836227417,
    "generate_time": 1.5727603435516357,
    "total_time": 1.7893881797790527,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "约 98%",
    "context": [
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "经过微调后",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      }
    ]
  },
  {
    "id": "q39",
    "model": "baichuan2-13b-chat",
    "query": "SavedModel 被保存到哪个目录？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.1733400821685791,
    "generate_time": 1.5980253219604492,
    "total_time": 1.7713654041290283,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "save/fine_tuning",
    "context": [
      {
        "content": "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      },
      {
        "content": "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段"
      },
      {
        "content": "tf.saved_model.save(model, saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段"
      }
    ]
  },
  {
    "id": "q40",
    "model": "baichuan2-13b-chat",
    "query": "Android 项目中应将 model.tflite 放置到哪个 assets 路径？",
    "answer": "模型调用错误: Error code: 429 - {'error': {'code': 'rate_limit', 'param': None, 'type': 'rate_limit_error', 'message': 'Request too frequent, please try again later'}}",
    "retrieve_time": 0.22121453285217285,
    "generate_time": 1.508880615234375,
    "total_time": 1.7300951480865479,
    "tokens_out": 0,
    "tokens_in": 0,
    "ground_truth": "android/start/app/src/main/assets/",
    "context": [
      {
        "content": "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段"
      },
      {
        "content": "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段"
      }
    ]
  },
  {
    "id": "q21",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 项目的技能目标中提到需要熟练使用哪款 IDE？",
    "answer": "根据提供的资料，没有具体提到需要熟练使用哪款 IDE 来开发 TensorFlow Lite 项目。因此，无法从资料中确定特定的 IDE。建议参考项目的其他文档或说明，可能会有更详细的开发环境要求。\n\n简要回答：不知道。资料中未提及具体的 IDE。",
    "retrieve_time": 0.2521815299987793,
    "generate_time": 2.860100507736206,
    "total_time": 3.1122820377349854,
    "tokens_out": 66,
    "tokens_in": 196,
    "ground_truth": "Android Studio",
    "context": [
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "项目8 TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段"
      },
      {
        "content": "8.1 认识TensorFlow Lite",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q22",
    "model": "yi-34b-chat",
    "query": "TensorFlow 生态中用于高性能服务器端部署的平台叫什么？",
    "answer": "TensorFlow 生态中用于高性能服务器端部署的平台叫 TensorFlow Serving。",
    "retrieve_time": 0.21046829223632812,
    "generate_time": 1.5626487731933594,
    "total_time": 1.7731170654296875,
    "tokens_out": 21,
    "tokens_in": 452,
    "ground_truth": "TensorFlow Serving",
    "context": [
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段"
      },
      {
        "content": "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q23",
    "model": "yi-34b-chat",
    "query": "哪家公司被提及使用 TensorFlow Lite 进行 OCR 处理？",
    "answer": "根据提供的资料，网易被提及使用 TensorFlow Lite 进行 OCR 处理。",
    "retrieve_time": 0.16713476181030273,
    "generate_time": 1.7519123554229736,
    "total_time": 1.9190471172332764,
    "tokens_out": 22,
    "tokens_in": 413,
    "ground_truth": "网易",
    "context": [
      {
        "content": "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段"
      },
      {
        "content": "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段"
      },
      {
        "content": "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段"
      },
      {
        "content": "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段"
      }
    ]
  },
  {
    "id": "q24",
    "model": "yi-34b-chat",
    "query": "在 32 位安卓平台，仅核心运行时代码大小约为多少 KB？",
    "answer": "在 32 位安卓平台，仅核心运行时代码大小约为 100 KB。",
    "retrieve_time": 0.20302104949951172,
    "generate_time": 1.6090729236602783,
    "total_time": 1.81209397315979,
    "tokens_out": 24,
    "tokens_in": 334,
    "ground_truth": "约 100 KB",
    "context": [
      {
        "content": "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段"
      },
      {
        "content": "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段"
      },
      {
        "content": "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段"
      },
      {
        "content": "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段"
      }
    ]
  },
  {
    "id": "q25",
    "model": "yi-34b-chat",
    "query": "TensorFlow Lite 工作流程的第四步强调了哪项操作？",
    "answer": "根据提供的资料，并没有详细列出TensorFlow Lite工作流程的具体每个步骤的内容，包括第四步的详细操作。因此，基于现有资料，无法确定第四步强调的操作。\n\n**回答: 不知道**",
    "retrieve_time": 0.22408366203308105,
    "generate_time": 2.3752222061157227,
    "total_time": 2.5993058681488037,
    "tokens_out": 49,
    "tokens_in": 164,
    "ground_truth": "优化模型（size/performance trade-off）",
    "context": [
      {
        "content": "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段"
      },
      {
        "content": "8.3 任务1：TensorFlow Lite开发工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段"
      },
      {
        "content": "图8-3 TensorFlow Lite 的工作流程",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段"
      },
      {
        "content": "掌握TensorFlow Lite的整体架构",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段"
      }
    ]
  },
  {
    "id": "q26",
    "model": "yi-34b-chat",
    "query": "训练集包含多少张花卉图片？",
    "answer": "根据参考资料，花会数据集每个类别的花平均有734张图片。假设数据集包含多个类别，我们需要知道具体有多少种类别的花。不过，参考资料并未明确提供具体类别数量。\n\n但是，如果我们假设数据集包含5种类别的花（这是常见的假设，基于一些公开使用的情况），那么总图片数量大约是：\n\n734张/类别 × 5类别 = 3670张图片。\n\n因此，**训练集大约包含3670张花卉图片**。如果实际类别数量不同，这个数字会有所变化。",
    "retrieve_time": 0.20406532287597656,
    "generate_time": 4.824083089828491,
    "total_time": 5.028148412704468,
    "tokens_out": 129,
    "tokens_in": 204,
    "ground_truth": "2939 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "fname=\"flower_photos.tgz\",",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段"
      }
    ]
  },
  {
    "id": "q27",
    "model": "yi-34b-chat",
    "query": "验证集包含多少张花卉图片？",
    "answer": "根据提供的资料，没有具体提到验证集包含多少张花卉图片。资料主要描述了数据集的下载来源和内容，但没有说明验证集的详细信息。因此，**不知道**验证集具体包含多少张花卉图片。",
    "retrieve_time": 0.18758773803710938,
    "generate_time": 2.2988669872283936,
    "total_time": 2.486454725265503,
    "tokens_out": 51,
    "tokens_in": 201,
    "ground_truth": "731 张",
    "context": [
      {
        "content": "我们将使用带有标注的花会数据集",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s"
      },
      {
        "content": "花会数据集可以载TenzeFullo官网下载",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s"
      },
      {
        "content": "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段"
      },
      {
        "content": "MobileNet V2来识别花会",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s"
      }
    ]
  },
  {
    "id": "q28",
    "model": "yi-34b-chat",
    "query": "示例代码中保存类别标签的文件名是什么？",
    "answer": "示例代码中保存类别标签的文件名是 'labels.txt'。",
    "retrieve_time": 0.16812682151794434,
    "generate_time": 1.3070602416992188,
    "total_time": 1.475187063217163,
    "tokens_out": 18,
    "tokens_in": 147,
    "ground_truth": "labels.txt",
    "context": [
      {
        "content": "with open('labels.txt', 'w') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段"
      },
      {
        "content": "return \"labels.txt\";",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段"
      },
      {
        "content": "默认是将图片分类到1000类",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      }
    ]
  },
  {
    "id": "q29",
    "model": "yi-34b-chat",
    "query": "MobileNet V2 基础模型的输入形状 IMG_SHAPE 被设置为多少？",
    "answer": "根据提供的资料，并没有具体说明IMG_SHAPE的值。资料中仅提到`base_model`使用了`MobileNetV2`并设置了`input_shape=IMG_SHAPE`，但未给出IMG_SHAPE的具体数值。\n\n回答: 不知道IMG_SHAPE的具体值，因为资料中未提供。",
    "retrieve_time": 0.1827549934387207,
    "generate_time": 2.390850782394409,
    "total_time": 2.57360577583313,
    "tokens_out": 82,
    "tokens_in": 230,
    "ground_truth": "(224, 224, 3)",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      }
    ]
  },
  {
    "id": "q30",
    "model": "yi-34b-chat",
    "query": "为何在实例化 MobileNet V2 时将 include_top 参数设为 False？",
    "answer": "在实例化 MobileNet V2 时将 include_top 参数设为 False，是为了移除模型顶部的最终分类层（即分类到1000类的那一层）。这样做是为了能够根据具体任务自定义输出层。例如，在只有5类分类任务的情况下，需要在基础模型上添加一个新的输出层来适应新的分类数目。设置 include_top=False 允许用户根据自己的需求重新定义模型的顶层结构。",
    "retrieve_time": 0.19520926475524902,
    "generate_time": 3.4697306156158447,
    "total_time": 3.6649398803710938,
    "tokens_out": 98,
    "tokens_in": 269,
    "ground_truth": "去除原有 1000 类分类头，以便添加自定义输出层",
    "context": [
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "使用少量顶层而不是整个MobileNet模型",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      },
      {
        "content": "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段"
      }
    ]
  },
  {
    "id": "q31",
    "model": "yi-34b-chat",
    "query": "将 base_model.trainable 设为 False 的目的是什么？",
    "answer": "将 base_model.trainable 设为 False 的目的是在训练过程中不更新预训练基础模型的权重，从而保留其在大规模数据上预训练的优势。这样仅训练新增的分类器或其他层，避免对基础模型的参数进行修改。",
    "retrieve_time": 0.20454907417297363,
    "generate_time": 2.450950860977173,
    "total_time": 2.6554999351501465,
    "tokens_out": 57,
    "tokens_in": 239,
    "ground_truth": "冻结预训练权重，避免在初始训练阶段被更新",
    "context": [
      {
        "content": "base_model.trainable = False",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "base_model.trainable = True",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段"
      },
      {
        "content": "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段"
      }
    ]
  },
  {
    "id": "q32",
    "model": "yi-34b-chat",
    "query": "自定义网络最后一层使用的激活函数是什么？",
    "answer": "根据提供的资料，没有明确提到自定义网络最后一层使用的激活函数是什么。资料中只说明最后是一个五个节点的输出层，但没有指定激活函数的类型。\n\n回答: 不知道。",
    "retrieve_time": 0.17517590522766113,
    "generate_time": 1.66804838180542,
    "total_time": 1.843224287033081,
    "tokens_out": 44,
    "tokens_in": 243,
    "ground_truth": "softmax",
    "context": [
      {
        "content": "表示不需要远有模型中最后的神经网络层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s"
      },
      {
        "content": "最后是一个五个节点的输出层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s"
      },
      {
        "content": "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段"
      },
      {
        "content": "基础模型的最后几层",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s"
      }
    ]
  },
  {
    "id": "q33",
    "model": "yi-34b-chat",
    "query": "初始训练阶段采用的优化器是哪一个？",
    "answer": "根据提供的资料，初始训练阶段采用的优化器是 **Adam**，其学习率设置为 **1e-5**。这是通过以下代码实现的：\n\n```python\noptimizer = tf.keras.optimizers.Adam(1e-5)\n```\n\n因此，优化器是 Adam (学习率为 1e-5)。",
    "retrieve_time": 0.18487119674682617,
    "generate_time": 2.3119986057281494,
    "total_time": 2.4968698024749756,
    "tokens_out": 77,
    "tokens_in": 205,
    "ground_truth": "Adam",
    "context": [
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "在训练之前先编译模型，损失函数使用类别交叉熵。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段"
      },
      {
        "content": "optimizer = tf.keras.optimizers.Adam(1e-5),",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q34",
    "model": "yi-34b-chat",
    "query": "模型中不可训练参数（Non-trainable params）的数量是多少？",
    "answer": "模型中不可训练参数（Non-trainable params）的数量是 2,257,984。",
    "retrieve_time": 0.22586417198181152,
    "generate_time": 1.7314298152923584,
    "total_time": 1.95729398727417,
    "tokens_out": 26,
    "tokens_in": 203,
    "ground_truth": "2,257,984",
    "context": [
      {
        "content": "Non-trainable params: 2,257,984",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段"
      },
      {
        "content": "Trainable params: 368,837",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段"
      },
      {
        "content": "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段"
      },
      {
        "content": "设置在训练中基础模型的各项参数变量",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s"
      }
    ]
  },
  {
    "id": "q35",
    "model": "yi-34b-chat",
    "query": "微调 (fine-tuning) 时从第几层开始解冻？",
    "answer": "根据提供的资料，微调（fine-tuning）时从指定的一层开始解冻，具体是从标记为 `fine_tune_at` 的层开始解冻。资料提到“Freeze all the layers before the `fine_tune_at` layer”，这意味着从 `fine_tune_at` 这一层开始及其之后的层将取消冻结，进行微调。\n\n回答: 微调时从标记为 `fine_tune_at` 的层开始解冻。",
    "retrieve_time": 0.17909789085388184,
    "generate_time": 3.320054769515991,
    "total_time": 3.499152660369873,
    "tokens_out": 116,
    "tokens_in": 205,
    "ground_truth": "第 100 层 (fine_tune_at = 100) 之后",
    "context": [
      {
        "content": "首先取消冻结模型的顶层，代码如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段"
      },
      {
        "content": "# Fine tune from this layer onwards",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段"
      },
      {
        "content": "# Freeze all the layers before the `fine_tune_at` layer",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      }
    ]
  },
  {
    "id": "q36",
    "model": "yi-34b-chat",
    "query": "MobileNet V2 基础模型总层数是多少？",
    "answer": "根据提供的资料，没有具体信息说明MobileNet V2基础模型的总层数。资料主要描述了模型的使用和修改方法，但没有提及模型的具体层数。因此，无法从资料中确定MobileNet V2的基础模型总层数。\n\n回答: 不知道",
    "retrieve_time": 0.28591394424438477,
    "generate_time": 2.1655280590057373,
    "total_time": 2.451442003250122,
    "tokens_out": 62,
    "tokens_in": 203,
    "ground_truth": "155 层",
    "context": [
      {
        "content": "MobileNet V2模型网络",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s"
      },
      {
        "content": "MobileNet V2是基于一个流线型的价格",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s"
      },
      {
        "content": "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段"
      },
      {
        "content": "我们选择MobileNet V2进行千亿学习",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s"
      }
    ]
  },
  {
    "id": "q37",
    "model": "yi-34b-chat",
    "query": "微调阶段使用的学习率被设置为多少？",
    "answer": "不知道。参考资料中未提及微调阶段具体使用的学习率。",
    "retrieve_time": 0.2187485694885254,
    "generate_time": 1.3348848819732666,
    "total_time": 1.553633451461792,
    "tokens_out": 16,
    "tokens_in": 276,
    "ground_truth": "1e-5",
    "context": [
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      },
      {
        "content": "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段"
      }
    ]
  },
  {
    "id": "q38",
    "model": "yi-34b-chat",
    "query": "微调后模型的验证精度大约达到多少？",
    "answer": "根据提供的资料，微调后模型的精度几乎达到98%。因此，可以推测微调后模型的验证精度大约为98%。\n\n回答: 大约达到98%。",
    "retrieve_time": 0.23184800148010254,
    "generate_time": 1.62227463722229,
    "total_time": 1.8541226387023926,
    "tokens_out": 42,
    "tokens_in": 212,
    "ground_truth": "约 98%",
    "context": [
      {
        "content": "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段"
      },
      {
        "content": "经过微调后",
        "source": "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s"
      },
      {
        "content": "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段"
      },
      {
        "content": "微调",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段"
      }
    ]
  },
  {
    "id": "q39",
    "model": "yi-34b-chat",
    "query": "SavedModel 被保存到哪个目录？",
    "answer": "SavedModel 被保存到由 `saved_model_dir` 指定的目录，该目录是一个绝对路径的字符串。例如：`tf.saved_model.save(model, saved_model_dir)` 中，`saved_model_dir` 是你指定的目录路径。\n\n回答: SavedModel 被保存到由 `saved_model_dir` 指定的目录。",
    "retrieve_time": 0.18221521377563477,
    "generate_time": 2.4908053874969482,
    "total_time": 2.673020601272583,
    "tokens_out": 90,
    "tokens_in": 203,
    "ground_truth": "save/fine_tuning",
    "context": [
      {
        "content": "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段"
      },
      {
        "content": "转换转换 SavedModel示例如下：",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段"
      },
      {
        "content": "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段"
      },
      {
        "content": "tf.saved_model.save(model, saved_model_dir)",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段"
      }
    ]
  },
  {
    "id": "q40",
    "model": "yi-34b-chat",
    "query": "Android 项目中应将 model.tflite 放置到哪个 assets 路径？",
    "answer": "根据提供的资料，在Android项目中应将`model.tflite`文件放置到以下路径：\n\n`/android/start/app/src/main/assets/`\n\n这是资料内容1中明确指出的路径。",
    "retrieve_time": 0.19449281692504883,
    "generate_time": 1.9635496139526367,
    "total_time": 2.1580424308776855,
    "tokens_out": 53,
    "tokens_in": 210,
    "ground_truth": "android/start/app/src/main/assets/",
    "context": [
      {
        "content": "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段"
      },
      {
        "content": "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段"
      },
      {
        "content": "with open('model.tflite', 'wb') as f:",
        "source": "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段"
      }
    ]
  }
]