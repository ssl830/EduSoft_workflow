# 模型评估报告

## 概览

- 评估模型数: 2
- 测试问题数: 10

## 评估指标

| 模型         |   BERTScore-F1 ↑ |   Source Recall ↑ |   Rouge-L ↑ |   平均延迟(s) ↓ |   输出Token数 ↓ |
|:-------------|-----------------:|------------------:|------------:|----------------:|----------------:|
| deepseek-v3  |            0.614 |             0.05  |       0.399 |            6.06 |              54 |
| qwen-7b-chat |            0.621 |             0.054 |       0.423 |            4.87 |              51 |


## 详细分析


### 响应延迟对比

![响应延迟对比](./benchmark_latency.png)


### 回答质量对比

![回答质量对比](./benchmark_quality.png)


### 典型问题回答样本


#### 问题: TensorFlow Lite 主要面向哪三类设备进行模型部署？

**参考答案**: 移动设备（Android、iOS）、嵌入式设备以及微控制器（MCU）


**deepseek-v3回答**:
TensorFlow Lite 主要面向以下三类设备进行模型部署：  
1. 移动设备（Mobile，如 Android、iOS）  
2. 嵌入式设备（Embedded）  
3. 物联网设备（IoT，包括极小的 MCU 设备）  

（依据参考资料内容 2 和内容 4 总结）


**qwen-7b-chat回答**:
TensorFlow Lite 主要面向以下三类设备进行模型部署：移动设备（如智能手机）、嵌入式设备以及物联网(IoT)设备。


#### 问题: 在 Python 中将 SavedModel 转换为 TFLite 模型应使用哪个类？

**参考答案**: tf.lite.TFLiteConverter


**deepseek-v3回答**:
在 Python 中将 SavedModel 转换为 TFLite 模型应使用 `tf.lite.TFLiteConverter` 类，并调用其 `from_saved_model()` 方法。具体代码如下：

```python
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
```

其中 `saved_model_dir` 是 SavedModel 的目录路径。


**qwen-7b-chat回答**:
在 Python 中将 SavedModel 转换为 TFLite 模型应使用 `tf.lite.TFLiteConverter` 类。具体来说，可以通过调用 `TFLiteConverter.from_saved_model()` 方法来实现转换，其中需要提供SavedModel目录的路径作为参数。例如：

```python
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
```

这里的 `saved_model_dir` 是指向您的 SavedModel 文件夹的路径。


#### 问题: 全球约有多少台设备部署了 TensorFlow Lite？

**参考答案**: 超过 40 亿台设备


**deepseek-v3回答**:
根据参考资料，全球有超过40亿台设备部署了TensorFlow Lite（如内容1、内容2和内容4所述）。


**qwen-7b-chat回答**:
全球超过40亿的设备上部署了TensorFlow Lite。
